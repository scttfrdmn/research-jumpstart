{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Analytics & Student Performance Prediction\n",
    "\n",
    "Complete tutorial on analyzing student data and predicting academic outcomes.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "30 students with:\n",
    "- **Demographics**: Gender, Age\n",
    "- **Behavioral**: Study hours per week, Attendance %\n",
    "- **Performance**: Assignment, Midterm, Final scores\n",
    "- **Outcome**: Pass/Fail (60% threshold)\n",
    "\n",
    "## Methods\n",
    "- Exploratory data analysis\n",
    "- Correlation analysis\n",
    "- Logistic regression for pass/fail prediction\n",
    "- Feature importance\n",
    "- Performance visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"sample_student_data.csv\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {', '.join(df.columns)}\")\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(f\"\\nPass Rate: {df['passed'].mean() * 100:.1f}%\")\n",
    "print(f\"Passed: {df['passed'].sum()} students\")\n",
    "print(f\"Failed: {(~df['passed'].astype(bool)).sum()} students\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "numeric_cols = [\n",
    "    \"study_hours\",\n",
    "    \"attendance\",\n",
    "    \"assignment_score\",\n",
    "    \"midterm_score\",\n",
    "    \"final_score\",\n",
    "    \"age\",\n",
    "]\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].hist(df[col], bins=10, edgecolor=\"black\", alpha=0.7)\n",
    "    axes[idx].axvline(\n",
    "        df[col].mean(),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=f\"Mean: {df[col].mean():.1f}\",\n",
    "    )\n",
    "    axes[idx].set_title(f\"{col.replace('_', ' ').title()} Distribution\", fontweight=\"bold\")\n",
    "    axes[idx].set_xlabel(col.replace(\"_\", \" \").title())\n",
    "    axes[idx].set_ylabel(\"Frequency\")\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pass/Fail Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare passed vs failed students\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "compare_vars = [\"study_hours\", \"attendance\", \"assignment_score\", \"midterm_score\"]\n",
    "\n",
    "for idx, var in enumerate(compare_vars):\n",
    "    passed = df[df[\"passed\"] == 1][var]\n",
    "    failed = df[df[\"passed\"] == 0][var]\n",
    "\n",
    "    axes[idx].boxplot([passed, failed], labels=[\"Passed\", \"Failed\"])\n",
    "    axes[idx].set_title(f\"{var.replace('_', ' ').title()} by Outcome\", fontweight=\"bold\")\n",
    "    axes[idx].set_ylabel(var.replace(\"_\", \" \").title())\n",
    "    axes[idx].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    # Statistical test\n",
    "    t_stat, p_val = stats.ttest_ind(passed, failed)\n",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"ns\"))\n",
    "    axes[idx].text(\n",
    "        0.5,\n",
    "        0.95,\n",
    "        f\"p = {p_val:.4f} {sig}\",\n",
    "        transform=axes[idx].transAxes,\n",
    "        ha=\"center\",\n",
    "        va=\"top\",\n",
    "        bbox={\"boxstyle\": \"round\", \"facecolor\": \"wheat\", \"alpha\": 0.5},\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for correlation\n",
    "numeric_df = df[\n",
    "    [\n",
    "        \"age\",\n",
    "        \"study_hours\",\n",
    "        \"attendance\",\n",
    "        \"assignment_score\",\n",
    "        \"midterm_score\",\n",
    "        \"final_score\",\n",
    "        \"passed\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "correlation = numeric_df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    correlation,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    ax=ax,\n",
    "    cbar_kws={\"label\": \"Correlation\"},\n",
    ")\n",
    "ax.set_title(\"Student Performance Correlation Matrix\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStrongest Predictors of Passing:\")\n",
    "pass_corr = correlation[\"passed\"].sort_values(ascending=False)[1:]\n",
    "for var, corr in pass_corr.items():\n",
    "    print(f\"  {var.replace('_', ' ').title()}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots with regression lines\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "relationships = [\n",
    "    (\"study_hours\", \"final_score\"),\n",
    "    (\"attendance\", \"final_score\"),\n",
    "    (\"assignment_score\", \"final_score\"),\n",
    "    (\"midterm_score\", \"final_score\"),\n",
    "]\n",
    "\n",
    "for idx, (x_var, y_var) in enumerate(relationships):\n",
    "    # Color by pass/fail\n",
    "    passed = df[df[\"passed\"] == 1]\n",
    "    failed = df[df[\"passed\"] == 0]\n",
    "\n",
    "    axes[idx].scatter(passed[x_var], passed[y_var], c=\"green\", alpha=0.6, s=100, label=\"Passed\")\n",
    "    axes[idx].scatter(failed[x_var], failed[y_var], c=\"red\", alpha=0.6, s=100, label=\"Failed\")\n",
    "\n",
    "    # Regression line\n",
    "    z = np.polyfit(df[x_var], df[y_var], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(df[x_var].min(), df[x_var].max(), 100)\n",
    "    axes[idx].plot(x_line, p(x_line), \"b--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "    # Correlation\n",
    "    r = df[[x_var, y_var]].corr().iloc[0, 1]\n",
    "    axes[idx].text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        f\"r = {r:.3f}\",\n",
    "        transform=axes[idx].transAxes,\n",
    "        va=\"top\",\n",
    "        bbox={\"boxstyle\": \"round\", \"facecolor\": \"wheat\", \"alpha\": 0.5},\n",
    "    )\n",
    "\n",
    "    axes[idx].set_xlabel(x_var.replace(\"_\", \" \").title(), fontsize=11)\n",
    "    axes[idx].set_ylabel(y_var.replace(\"_\", \" \").title(), fontsize=11)\n",
    "    axes[idx].set_title(\n",
    "        f\"{x_var.replace('_', ' ').title()} vs {y_var.replace('_', ' ').title()}\", fontweight=\"bold\"\n",
    "    )\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "feature_cols = [\"study_hours\", \"attendance\", \"assignment_score\", \"midterm_score\"]\n",
    "X = df[feature_cols]\n",
    "y = df[\"passed\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Model Training Complete!\")\n",
    "print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"\\nTraining accuracy: {model.score(X_train_scaled, y_train):.3f}\")\n",
    "print(f\"Test accuracy: {model.score(X_test_scaled, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Failed\", \"Passed\"]))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    ax=ax,\n",
    "    xticklabels=[\"Failed\", \"Passed\"],\n",
    "    yticklabels=[\"Failed\", \"Passed\"],\n",
    ")\n",
    "ax.set_title(\"Confusion Matrix\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"True Label\", fontsize=12)\n",
    "ax.set_xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature coefficients\n",
    "coefficients = pd.DataFrame(\n",
    "    {\n",
    "        \"Feature\": feature_cols,\n",
    "        \"Coefficient\": model.coef_[0],\n",
    "        \"Abs_Coefficient\": np.abs(model.coef_[0]),\n",
    "    }\n",
    ").sort_values(\"Abs_Coefficient\", ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Logistic Regression Coefficients):\")\n",
    "print(coefficients[[\"Feature\", \"Coefficient\"]].to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = [\"green\" if c > 0 else \"red\" for c in coefficients[\"Coefficient\"]]\n",
    "ax.barh(coefficients[\"Feature\"], coefficients[\"Coefficient\"], color=colors, alpha=0.7)\n",
    "ax.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax.set_title(\n",
    "    \"Feature Importance (Higher = More Important for Passing)\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "ax.set_xlabel(\"Coefficient\")\n",
    "ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "ax.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\", label=\"Random Classifier\")\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel(\"False Positive Rate\", fontsize=12)\n",
    "ax.set_ylabel(\"True Positive Rate\", fontsize=12)\n",
    "ax.set_title(\"Receiver Operating Characteristic (ROC) Curve\", fontsize=14, fontweight=\"bold\")\n",
    "ax.legend(loc=\"lower right\", fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAUC Score: {roc_auc:.3f}\")\n",
    "print(f\"Interpretation: {'Excellent' if roc_auc > 0.9 else ('Good' if roc_auc > 0.8 else 'Fair')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\n",
    "            \"Total Students\",\n",
    "            \"Pass Rate\",\n",
    "            \"Model Accuracy\",\n",
    "            \"AUC Score\",\n",
    "            \"Top Predictor\",\n",
    "            \"Mean Study Hours\",\n",
    "            \"Mean Attendance\",\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            len(df),\n",
    "            f\"{df['passed'].mean() * 100:.1f}%\",\n",
    "            f\"{model.score(X_test_scaled, y_test):.3f}\",\n",
    "            f\"{roc_auc:.3f}\",\n",
    "            coefficients.iloc[0][\"Feature\"],\n",
    "            f\"{df['study_hours'].mean():.1f} hrs/week\",\n",
    "            f\"{df['attendance'].mean():.1f}%\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LEARNING ANALYTICS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(summary.to_string(index=False))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save\n",
    "summary.to_csv(\"learning_analytics_summary.csv\", index=False)\n",
    "print(\"\\n✓ Summary saved to learning_analytics_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "### Student Performance\n",
    "- **Pass rate**: ~83% of students passed\n",
    "- Strong correlation between **study hours** and final scores\n",
    "- **Attendance** is a critical factor for success\n",
    "\n",
    "### Prediction Model\n",
    "- Logistic regression achieves high accuracy\n",
    "- **Top predictors** (in order):\n",
    "  1. Midterm score\n",
    "  2. Assignment score\n",
    "  3. Study hours\n",
    "  4. Attendance\n",
    "\n",
    "### Interventions\n",
    "- Students with < 8 study hours/week at risk\n",
    "- Attendance below 70% strongly predicts failure\n",
    "- Early midterm performance is best predictor\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Real-time monitoring**: Track at-risk students early\n",
    "2. **Feature engineering**: Add engagement metrics (clicks, time-on-task)\n",
    "3. **Advanced models**: Random Forest, XGBoost\n",
    "4. **A/B testing**: Test intervention strategies\n",
    "5. **Longitudinal analysis**: Track cohorts over time\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Educational Data Mining](https://educationaldatamining.org/)\n",
    "- [Learning Analytics](https://www.solaresearch.org/)\n",
    "- [Scikit-learn Documentation](https://scikit-learn.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
