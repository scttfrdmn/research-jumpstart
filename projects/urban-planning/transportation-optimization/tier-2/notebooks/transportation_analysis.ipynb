{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transportation Flow Analysis with AWS\n",
    "\n",
    "This notebook demonstrates traffic flow analysis using AWS services:\n",
    "- Generate synthetic traffic data for urban network\n",
    "- Upload data to S3\n",
    "- Trigger Lambda processing\n",
    "- Query results from DynamoDB\n",
    "- Visualize traffic patterns and congestion\n",
    "\n",
    "**Prerequisites:**\n",
    "- AWS account configured\n",
    "- S3 bucket created\n",
    "- Lambda function deployed\n",
    "- DynamoDB table created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key, Attr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Configuration\n",
    "AWS_REGION = os.getenv('AWS_REGION', 'us-east-1')\n",
    "S3_BUCKET = os.getenv('S3_BUCKET_NAME', 'transportation-data-demo')\n",
    "S3_PREFIX = os.getenv('S3_RAW_PREFIX', 'raw/')\n",
    "DYNAMODB_TABLE = os.getenv('DYNAMODB_TABLE_NAME', 'TrafficAnalysis')\n",
    "LAMBDA_FUNCTION = os.getenv('LAMBDA_FUNCTION_NAME', 'analyze-traffic-flow')\n",
    "\n",
    "# Initialize AWS clients\n",
    "s3_client = boto3.client('s3', region_name=AWS_REGION)\n",
    "lambda_client = boto3.client('lambda', region_name=AWS_REGION)\n",
    "dynamodb = boto3.resource('dynamodb', region_name=AWS_REGION)\n",
    "\n",
    "print(f\"AWS Configuration:\")\n",
    "print(f\"  Region: {AWS_REGION}\")\n",
    "print(f\"  S3 Bucket: {S3_BUCKET}\")\n",
    "print(f\"  DynamoDB Table: {DYNAMODB_TABLE}\")\n",
    "print(f\"  Lambda Function: {LAMBDA_FUNCTION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Traffic Data\n",
    "\n",
    "Create synthetic traffic data for a simple urban network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urban_network(n_segments=20, seed=42):\n",
    "    \"\"\"\n",
    "    Generate a simple urban road network.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with segment information\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate grid network centered around San Francisco\n",
    "    base_lat = 37.7749\n",
    "    base_lon = -122.4194\n",
    "    \n",
    "    segments = []\n",
    "    \n",
    "    for i in range(n_segments):\n",
    "        segment = {\n",
    "            'segment_id': f'SEG-{i+1:03d}',\n",
    "            'latitude': base_lat + np.random.uniform(-0.05, 0.05),\n",
    "            'longitude': base_lon + np.random.uniform(-0.05, 0.05),\n",
    "            'speed_limit': np.random.choice([35, 45, 55, 65]),\n",
    "            'lanes': np.random.choice([2, 3, 4]),\n",
    "            'capacity': np.random.choice([2000, 2500, 3000]) * np.random.choice([2, 3, 4])\n",
    "        }\n",
    "        segments.append(segment)\n",
    "    \n",
    "    return pd.DataFrame(segments)\n",
    "\n",
    "# Generate network\n",
    "network_df = generate_urban_network(n_segments=20)\n",
    "print(f\"Generated urban network with {len(network_df)} segments\")\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_traffic_data(network_df, start_time, duration_hours=1, interval_minutes=5):\n",
    "    \"\"\"\n",
    "    Generate realistic traffic data for the network.\n",
    "    \n",
    "    Args:\n",
    "        network_df: DataFrame with segment information\n",
    "        start_time: Start datetime\n",
    "        duration_hours: Duration in hours\n",
    "        interval_minutes: Data collection interval\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with traffic observations\n",
    "    \"\"\"\n",
    "    observations = []\n",
    "    \n",
    "    # Generate timestamps\n",
    "    timestamps = pd.date_range(\n",
    "        start=start_time,\n",
    "        periods=int(duration_hours * 60 / interval_minutes),\n",
    "        freq=f'{interval_minutes}T'\n",
    "    )\n",
    "    \n",
    "    for timestamp in timestamps:\n",
    "        hour = timestamp.hour\n",
    "        \n",
    "        # Peak hours: higher traffic\n",
    "        is_peak = (7 <= hour < 9) or (17 <= hour < 19)\n",
    "        base_multiplier = 1.5 if is_peak else 0.8\n",
    "        \n",
    "        for _, segment in network_df.iterrows():\n",
    "            # Simulate traffic volume\n",
    "            base_volume = segment['capacity'] * base_multiplier * np.random.uniform(0.5, 1.2)\n",
    "            vehicle_count = int(base_volume * (interval_minutes / 60))  # Convert to interval\n",
    "            \n",
    "            # Calculate speed based on congestion\n",
    "            vc_ratio = vehicle_count / (segment['capacity'] * (interval_minutes / 60))\n",
    "            \n",
    "            # Speed decreases as V/C ratio increases\n",
    "            if vc_ratio < 0.5:\n",
    "                avg_speed = segment['speed_limit'] * np.random.uniform(0.95, 1.0)\n",
    "            elif vc_ratio < 0.8:\n",
    "                avg_speed = segment['speed_limit'] * np.random.uniform(0.7, 0.9)\n",
    "            elif vc_ratio < 1.0:\n",
    "                avg_speed = segment['speed_limit'] * np.random.uniform(0.5, 0.7)\n",
    "            else:\n",
    "                avg_speed = segment['speed_limit'] * np.random.uniform(0.3, 0.5)\n",
    "            \n",
    "            # Occupancy (percentage of road occupied)\n",
    "            occupancy = min(0.95, vc_ratio * 0.8)\n",
    "            \n",
    "            # Congestion level (0-5 scale)\n",
    "            if vc_ratio < 0.5:\n",
    "                congestion_level = 0\n",
    "            elif vc_ratio < 0.7:\n",
    "                congestion_level = 1\n",
    "            elif vc_ratio < 0.85:\n",
    "                congestion_level = 2\n",
    "            elif vc_ratio < 1.0:\n",
    "                congestion_level = 3\n",
    "            elif vc_ratio < 1.2:\n",
    "                congestion_level = 4\n",
    "            else:\n",
    "                congestion_level = 5\n",
    "            \n",
    "            observation = {\n",
    "                'timestamp': timestamp.isoformat(),\n",
    "                'segment_id': segment['segment_id'],\n",
    "                'latitude': segment['latitude'],\n",
    "                'longitude': segment['longitude'],\n",
    "                'vehicle_count': vehicle_count,\n",
    "                'avg_speed': round(avg_speed, 2),\n",
    "                'occupancy': round(occupancy, 3),\n",
    "                'congestion_level': congestion_level,\n",
    "                'speed_limit': segment['speed_limit'],\n",
    "                'capacity': segment['capacity'],\n",
    "                'lanes': segment['lanes']\n",
    "            }\n",
    "            observations.append(observation)\n",
    "    \n",
    "    return pd.DataFrame(observations)\n",
    "\n",
    "# Generate traffic data for peak morning hours\n",
    "start_time = datetime.now().replace(hour=7, minute=0, second=0, microsecond=0)\n",
    "traffic_df = generate_traffic_data(network_df, start_time, duration_hours=3, interval_minutes=5)\n",
    "\n",
    "print(f\"Generated {len(traffic_df)} traffic observations\")\n",
    "print(f\"Time range: {traffic_df['timestamp'].min()} to {traffic_df['timestamp'].max()}\")\n",
    "traffic_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot speed distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Speed distribution\n",
    "axes[0, 0].hist(traffic_df['avg_speed'], bins=30, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Average Speed (mph)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Speed Distribution')\n",
    "\n",
    "# Vehicle count distribution\n",
    "axes[0, 1].hist(traffic_df['vehicle_count'], bins=30, edgecolor='black', color='orange')\n",
    "axes[0, 1].set_xlabel('Vehicle Count')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Vehicle Count Distribution')\n",
    "\n",
    "# Congestion level distribution\n",
    "congestion_counts = traffic_df['congestion_level'].value_counts().sort_index()\n",
    "axes[1, 0].bar(congestion_counts.index, congestion_counts.values, color='red', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Congestion Level')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Congestion Level Distribution')\n",
    "\n",
    "# Average speed over time for sample segment\n",
    "sample_segment = traffic_df[traffic_df['segment_id'] == 'SEG-001'].copy()\n",
    "sample_segment['time'] = pd.to_datetime(sample_segment['timestamp'])\n",
    "axes[1, 1].plot(sample_segment['time'], sample_segment['avg_speed'], marker='o', color='green')\n",
    "axes[1, 1].set_xlabel('Time')\n",
    "axes[1, 1].set_ylabel('Average Speed (mph)')\n",
    "axes[1, 1].set_title('Speed Over Time (SEG-001)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save Data to CSV and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_dir = Path('../data')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "csv_filename = f'traffic_data_{timestamp_str}.csv'\n",
    "csv_path = output_dir / csv_filename\n",
    "\n",
    "traffic_df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved traffic data to: {csv_path}\")\n",
    "print(f\"File size: {csv_path.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "s3_key = f\"{S3_PREFIX}{csv_filename}\"\n",
    "\n",
    "try:\n",
    "    s3_client.upload_file(\n",
    "        str(csv_path),\n",
    "        S3_BUCKET,\n",
    "        s3_key,\n",
    "        ExtraArgs={\n",
    "            'ContentType': 'text/csv',\n",
    "            'Metadata': {\n",
    "                'uploaded_at': datetime.utcnow().isoformat(),\n",
    "                'records': str(len(traffic_df))\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    print(f\"✓ Uploaded to S3: s3://{S3_BUCKET}/{s3_key}\")\n",
    "    print(f\"  Lambda will automatically process this file.\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Upload failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wait for Lambda Processing\n",
    "\n",
    "Lambda is triggered automatically by S3 upload. Wait for processing to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lambda_processing(bucket, key, max_wait_seconds=60):\n",
    "    \"\"\"\n",
    "    Check if Lambda has processed the file by looking for results in S3.\n",
    "    \"\"\"\n",
    "    results_key = key.replace('raw/', 'results/').replace('.csv', '_analysis.json')\n",
    "    \n",
    "    print(f\"Waiting for Lambda to process file...\")\n",
    "    print(f\"Checking for results at: s3://{bucket}/{results_key}\")\n",
    "    \n",
    "    for i in range(max_wait_seconds):\n",
    "        try:\n",
    "            s3_client.head_object(Bucket=bucket, Key=results_key)\n",
    "            print(f\"\\n✓ Processing complete! Results found after {i+1} seconds.\")\n",
    "            return True\n",
    "        except:\n",
    "            if i % 5 == 0:\n",
    "                print(f\"  Waiting... ({i+1}s)\", end='\\r')\n",
    "            time.sleep(1)\n",
    "    \n",
    "    print(f\"\\n⚠ Processing did not complete within {max_wait_seconds} seconds.\")\n",
    "    print(\"  Check CloudWatch logs for errors.\")\n",
    "    return False\n",
    "\n",
    "# Wait for processing\n",
    "processing_complete = check_lambda_processing(S3_BUCKET, s3_key, max_wait_seconds=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Results from DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_dynamodb_results(table_name, limit=1000):\n",
    "    \"\"\"\n",
    "    Query all recent results from DynamoDB.\n",
    "    \"\"\"\n",
    "    table = dynamodb.Table(table_name)\n",
    "    \n",
    "    try:\n",
    "        response = table.scan(Limit=limit)\n",
    "        items = response.get('Items', [])\n",
    "        \n",
    "        # Handle pagination\n",
    "        while 'LastEvaluatedKey' in response and len(items) < limit:\n",
    "            response = table.scan(\n",
    "                Limit=limit - len(items),\n",
    "                ExclusiveStartKey=response['LastEvaluatedKey']\n",
    "            )\n",
    "            items.extend(response.get('Items', []))\n",
    "        \n",
    "        print(f\"Retrieved {len(items)} records from DynamoDB\")\n",
    "        return pd.DataFrame(items)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying DynamoDB: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Query results\n",
    "results_df = query_dynamodb_results(DYNAMODB_TABLE)\n",
    "\n",
    "if not results_df.empty:\n",
    "    print(f\"\\nResults summary:\")\n",
    "    print(f\"  Total records: {len(results_df)}\")\n",
    "    print(f\"  Unique segments: {results_df['segment_id'].nunique()}\")\n",
    "    print(f\"  Time range: {results_df['timestamp_iso'].min()} to {results_df['timestamp_iso'].max()}\")\n",
    "    results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Traffic Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    # Convert numeric columns\n",
    "    numeric_cols = ['avg_speed', 'vc_ratio', 'travel_time_index', 'reliability_score']\n",
    "    for col in numeric_cols:\n",
    "        if col in results_df.columns:\n",
    "            results_df[col] = pd.to_numeric(results_df[col])\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"=\"*70)\n",
    "    print(\"TRAFFIC ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nOverall Metrics:\")\n",
    "    print(f\"  Average Speed: {results_df['avg_speed'].mean():.2f} mph\")\n",
    "    print(f\"  Average V/C Ratio: {results_df['vc_ratio'].mean():.3f}\")\n",
    "    print(f\"  Average Travel Time Index: {results_df['travel_time_index'].mean():.3f}\")\n",
    "    print(f\"  Congestion Rate: {results_df['is_congested'].sum() / len(results_df) * 100:.1f}%\")\n",
    "    \n",
    "    # Level of Service distribution\n",
    "    print(f\"\\nLevel of Service Distribution:\")\n",
    "    los_dist = results_df['los'].value_counts().sort_index()\n",
    "    for los, count in los_dist.items():\n",
    "        pct = count / len(results_df) * 100\n",
    "        print(f\"  LOS {los}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Top congested segments\n",
    "    print(f\"\\nTop 5 Congested Segments:\")\n",
    "    top_congested = results_df.nlargest(5, 'vc_ratio')[['segment_id', 'vc_ratio', 'los', 'avg_speed']]\n",
    "    for _, row in top_congested.iterrows():\n",
    "        print(f\"  {row['segment_id']}: V/C={row['vc_ratio']:.3f}, LOS={row['los']}, Speed={row['avg_speed']:.1f} mph\")\n",
    "else:\n",
    "    print(\"No results available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # 1. LOS Distribution\n",
    "    los_counts = results_df['los'].value_counts().sort_index()\n",
    "    colors = ['green', 'lightgreen', 'yellow', 'orange', 'red', 'darkred']\n",
    "    axes[0, 0].bar(los_counts.index, los_counts.values, color=colors[:len(los_counts)])\n",
    "    axes[0, 0].set_xlabel('Level of Service')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    axes[0, 0].set_title('Level of Service Distribution')\n",
    "    \n",
    "    # 2. V/C Ratio Distribution\n",
    "    axes[0, 1].hist(results_df['vc_ratio'], bins=30, edgecolor='black', color='skyblue')\n",
    "    axes[0, 1].axvline(0.8, color='red', linestyle='--', label='Congestion Threshold')\n",
    "    axes[0, 1].set_xlabel('V/C Ratio')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Volume/Capacity Ratio Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # 3. Speed vs V/C Ratio\n",
    "    axes[0, 2].scatter(results_df['vc_ratio'], results_df['avg_speed'], \n",
    "                      c=results_df['vc_ratio'], cmap='RdYlGn_r', alpha=0.6)\n",
    "    axes[0, 2].set_xlabel('V/C Ratio')\n",
    "    axes[0, 2].set_ylabel('Average Speed (mph)')\n",
    "    axes[0, 2].set_title('Speed vs Congestion')\n",
    "    \n",
    "    # 4. Travel Time Index\n",
    "    axes[1, 0].hist(results_df['travel_time_index'], bins=30, edgecolor='black', color='coral')\n",
    "    axes[1, 0].axvline(1.0, color='green', linestyle='--', label='Free Flow')\n",
    "    axes[1, 0].set_xlabel('Travel Time Index')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Travel Time Index Distribution')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 5. Congestion by Segment\n",
    "    segment_congestion = results_df.groupby('segment_id')['is_congested'].mean().sort_values(ascending=False).head(10)\n",
    "    axes[1, 1].barh(range(len(segment_congestion)), segment_congestion.values, color='red', alpha=0.7)\n",
    "    axes[1, 1].set_yticks(range(len(segment_congestion)))\n",
    "    axes[1, 1].set_yticklabels(segment_congestion.index)\n",
    "    axes[1, 1].set_xlabel('Congestion Rate')\n",
    "    axes[1, 1].set_title('Top 10 Congested Segments')\n",
    "    \n",
    "    # 6. Reliability Score\n",
    "    axes[1, 2].hist(results_df['reliability_score'], bins=30, edgecolor='black', color='purple', alpha=0.7)\n",
    "    axes[1, 2].set_xlabel('Reliability Score')\n",
    "    axes[1, 2].set_ylabel('Frequency')\n",
    "    axes[1, 2].set_title('Travel Time Reliability')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/traffic_analysis_summary.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Figure saved to: ../data/traffic_analysis_summary.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    # Create network graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for each segment\n",
    "    for segment_id in results_df['segment_id'].unique():\n",
    "        segment_data = results_df[results_df['segment_id'] == segment_id].iloc[0]\n",
    "        G.add_node(segment_id,\n",
    "                  pos=(float(segment_data['longitude']), float(segment_data['latitude'])),\n",
    "                  avg_vc=float(results_df[results_df['segment_id'] == segment_id]['vc_ratio'].mean()))\n",
    "    \n",
    "    # Add edges (simplified - connect nearby nodes)\n",
    "    nodes = list(G.nodes())\n",
    "    for i, node1 in enumerate(nodes):\n",
    "        for node2 in nodes[i+1:i+4]:  # Connect to 3 nearest neighbors\n",
    "            if node2 in G.nodes():\n",
    "                G.add_edge(node1, node2)\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Get positions and colors\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    vc_ratios = [G.nodes[node]['avg_vc'] for node in G.nodes()]\n",
    "    \n",
    "    # Draw network\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.3, width=2)\n",
    "    nodes = nx.draw_networkx_nodes(G, pos, node_color=vc_ratios, \n",
    "                                   node_size=500, cmap='RdYlGn_r',\n",
    "                                   vmin=0, vmax=1.5)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(nodes, label='Average V/C Ratio')\n",
    "    plt.title('Urban Traffic Network - Congestion Heatmap', fontsize=16)\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.axis('on')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.savefig('../data/network_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Network heatmap saved to: ../data/network_heatmap.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results available for network visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty and 'timestamp_iso' in results_df.columns:\n",
    "    # Select a few representative segments\n",
    "    sample_segments = results_df['segment_id'].unique()[:5]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(sample_segments), 1, figsize=(14, 3*len(sample_segments)))\n",
    "    \n",
    "    if len(sample_segments) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, segment_id in enumerate(sample_segments):\n",
    "        segment_data = results_df[results_df['segment_id'] == segment_id].copy()\n",
    "        segment_data['time'] = pd.to_datetime(segment_data['timestamp_iso'])\n",
    "        segment_data = segment_data.sort_values('time')\n",
    "        \n",
    "        # Plot speed and V/C ratio\n",
    "        ax1 = axes[idx]\n",
    "        ax2 = ax1.twinx()\n",
    "        \n",
    "        line1 = ax1.plot(segment_data['time'], segment_data['avg_speed'], \n",
    "                        'b-o', label='Speed', markersize=4)\n",
    "        line2 = ax2.plot(segment_data['time'], segment_data['vc_ratio'], \n",
    "                        'r-s', label='V/C Ratio', markersize=4)\n",
    "        \n",
    "        ax1.set_xlabel('Time')\n",
    "        ax1.set_ylabel('Speed (mph)', color='b')\n",
    "        ax2.set_ylabel('V/C Ratio', color='r')\n",
    "        ax1.set_title(f'Traffic Metrics Over Time - {segment_id}')\n",
    "        ax1.tick_params(axis='y', labelcolor='b')\n",
    "        ax2.tick_params(axis='y', labelcolor='r')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add legend\n",
    "        lines = line1 + line2\n",
    "        labels = [l.get_label() for l in lines]\n",
    "        ax1.legend(lines, labels, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/time_series_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Time series plot saved to: ../data/time_series_analysis.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient data for time series analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    # Export to CSV\n",
    "    output_csv = f'../data/analysis_results_{timestamp_str}.csv'\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Results exported to: {output_csv}\")\n",
    "    \n",
    "    # Create summary report\n",
    "    summary = {\n",
    "        'analysis_timestamp': datetime.now().isoformat(),\n",
    "        'total_records': len(results_df),\n",
    "        'unique_segments': results_df['segment_id'].nunique(),\n",
    "        'metrics': {\n",
    "            'avg_speed': float(results_df['avg_speed'].mean()),\n",
    "            'avg_vc_ratio': float(results_df['vc_ratio'].mean()),\n",
    "            'avg_tti': float(results_df['travel_time_index'].mean()),\n",
    "            'congestion_rate': float(results_df['is_congested'].sum() / len(results_df))\n",
    "        },\n",
    "        'los_distribution': results_df['los'].value_counts().to_dict(),\n",
    "        'top_congested_segments': results_df.nlargest(5, 'vc_ratio')[['segment_id', 'vc_ratio']].to_dict('records')\n",
    "    }\n",
    "    \n",
    "    output_json = f'../data/analysis_summary_{timestamp_str}.json'\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Summary report exported to: {output_json}\")\n",
    "else:\n",
    "    print(\"No results to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✓ Generated synthetic traffic data for urban network\n",
    "2. ✓ Uploaded data to S3\n",
    "3. ✓ Lambda automatically processed the data\n",
    "4. ✓ Queried results from DynamoDB\n",
    "5. ✓ Analyzed traffic metrics (LOS, V/C ratio, TTI)\n",
    "6. ✓ Visualized congestion patterns and network\n",
    "7. ✓ Exported results for further analysis\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Analyze multiple time periods to identify patterns\n",
    "- Implement predictive congestion models\n",
    "- Integrate with real traffic data sources\n",
    "- Create real-time monitoring dashboard\n",
    "- Move to Tier 3 for production deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
