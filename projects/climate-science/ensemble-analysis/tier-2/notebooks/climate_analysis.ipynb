{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Data Analysis with AWS S3 and Lambda\n",
    "## Tier 2 Project - Analyze processed climate data\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Download processed results from S3\n",
    "2. Analyze climate statistics\n",
    "3. Create visualizations\n",
    "4. Export reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import necessary libraries and configure AWS access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up S3 connection parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configuration from environment\n",
    "AWS_REGION = os.environ.get('AWS_REGION', 'us-east-1')\n",
    "BUCKET_NAME = os.environ.get('AWS_S3_BUCKET', 'climate-data-unknown')\n",
    "LAMBDA_FUNCTION = os.environ.get('AWS_LAMBDA_FUNCTION', 'process-climate-data')\n",
    "\n",
    "print(f\"AWS Region: {AWS_REGION}\")\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"Lambda Function: {LAMBDA_FUNCTION}\")\n",
    "\n",
    "# Create S3 client\n",
    "s3 = boto3.client('s3', region_name=AWS_REGION)\n",
    "print(\"\\n✓ AWS S3 client configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: List Available Results\n",
    "\n",
    "Check what results are available in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_s3_files(bucket, prefix='results/'):\n",
    "    \"\"\"List files in S3 bucket.\"\"\"\n",
    "    try:\n",
    "        response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "        \n",
    "        if 'Contents' not in response:\n",
    "            print(f\"No files found in {prefix}\")\n",
    "            return []\n",
    "        \n",
    "        files = []\n",
    "        for obj in response['Contents']:\n",
    "            files.append({\n",
    "                'key': obj['Key'],\n",
    "                'size_mb': obj['Size'] / 1e6,\n",
    "                'modified': obj['LastModified']\n",
    "            })\n",
    "        \n",
    "        return files\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing files: {e}\")\n",
    "        return []\n",
    "\n",
    "# List results\n",
    "results_files = list_s3_files(BUCKET_NAME, 'results/')\n",
    "\n",
    "print(f\"Found {len(results_files)} result files:\\n\")\n",
    "for f in results_files[:10]:  # Show first 10\n",
    "    print(f\"  {f['key']} ({f['size_mb']:.2f}MB)\")\n",
    "\n",
    "if len(results_files) > 10:\n",
    "    print(f\"  ... and {len(results_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Results\n",
    "\n",
    "Download processed results from S3 to local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_s3_results(bucket, prefix='results/', output_dir='./results'):\n",
    "    \"\"\"Download all results from S3.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    files = list_s3_files(bucket, prefix)\n",
    "    downloaded = []\n",
    "    \n",
    "    for f in files:\n",
    "        try:\n",
    "            output_path = output_dir / Path(f['key']).name\n",
    "            print(f\"Downloading: {f['key']}\")\n",
    "            \n",
    "            s3.download_file(bucket, f['key'], str(output_path))\n",
    "            downloaded.append(str(output_path))\n",
    "            print(f\"  ✓ Saved to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\n✓ Downloaded {len(downloaded)} files\")\n",
    "    return downloaded\n",
    "\n",
    "# Download results\n",
    "downloaded_files = download_s3_results(BUCKET_NAME)\n",
    "\n",
    "if not downloaded_files:\n",
    "    print(\"\\n⚠️  No results to download. Make sure to run setup_guide.md first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Parse and Analyze Results\n",
    "\n",
    "Load and analyze the processed climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_files(file_paths):\n",
    "    \"\"\"Read JSON result files.\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data.append(json.load(f))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load results\n",
    "results_data = read_json_files(downloaded_files)\n",
    "print(f\"Loaded {len(results_data)} result files\\n\")\n",
    "\n",
    "# Display first result\n",
    "if results_data:\n",
    "    print(\"Sample result file:\")\n",
    "    print(json.dumps(results_data[0], indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Analysis DataFrame\n",
    "\n",
    "Organize results into a pandas DataFrame for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_dataframe(results_data):\n",
    "    \"\"\"Create DataFrame from results.\"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for result in results_data:\n",
    "        record = {'file': result.get('file', 'unknown')}\n",
    "        \n",
    "        # Extract temperature statistics\n",
    "        if 'statistics' in result and 'temperature' in result['statistics']:\n",
    "            temp = result['statistics']['temperature']\n",
    "            record['temp_mean'] = temp.get('mean')\n",
    "            record['temp_std'] = temp.get('std')\n",
    "            record['temp_min'] = temp.get('min')\n",
    "            record['temp_max'] = temp.get('max')\n",
    "        \n",
    "        # Extract precipitation statistics\n",
    "        if 'statistics' in result and 'precipitation' in result['statistics']:\n",
    "            precip = result['statistics']['precipitation']\n",
    "            record['precip_mean'] = precip.get('mean')\n",
    "            record['precip_std'] = precip.get('std')\n",
    "            record['precip_total'] = precip.get('total')\n",
    "        \n",
    "        records.append(record)\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Create DataFrame\n",
    "df = create_analysis_dataframe(results_data)\n",
    "print(f\"Analysis DataFrame shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Summary Statistics\n",
    "\n",
    "Calculate aggregate statistics across all processed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLIMATE DATA SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTotal files processed: {len(df)}\")\n",
    "\n",
    "# Temperature statistics\n",
    "if 'temp_mean' in df.columns:\n",
    "    print(\"\\nTemperature (K):\")\n",
    "    print(f\"  Mean of means: {df['temp_mean'].mean():.2f} K\")\n",
    "    print(f\"  Std dev: {df['temp_mean'].std():.2f} K\")\n",
    "    print(f\"  Range: {df['temp_min'].min():.2f} - {df['temp_max'].max():.2f} K\")\n",
    "\n",
    "# Precipitation statistics\n",
    "if 'precip_mean' in df.columns:\n",
    "    print(\"\\nPrecipitation (kg m-2 s-1):\")\n",
    "    print(f\"  Mean of means: {df['precip_mean'].mean():.2e}\")\n",
    "    print(f\"  Std dev: {df['precip_mean'].std():.2e}\")\n",
    "    print(f\"  Total: {df['precip_total'].sum():.2e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualizations\n",
    "\n",
    "Create publication-quality figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with multiple subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Climate Data Analysis Summary', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Temperature mean distribution\n",
    "if 'temp_mean' in df.columns:\n",
    "    axes[0, 0].hist(df['temp_mean'], bins=10, color='red', alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].set_xlabel('Temperature Mean (K)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Temperature Distribution')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Temperature range\n",
    "if 'temp_mean' in df.columns and 'temp_std' in df.columns:\n",
    "    x = range(len(df))\n",
    "    axes[0, 1].errorbar(x, df['temp_mean'], yerr=df['temp_std'], \n",
    "                        fmt='o', capsize=5, capthick=2, alpha=0.7)\n",
    "    axes[0, 1].set_xlabel('File Index')\n",
    "    axes[0, 1].set_ylabel('Temperature (K)')\n",
    "    axes[0, 1].set_title('Temperature with Uncertainty')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precipitation distribution\n",
    "if 'precip_mean' in df.columns:\n",
    "    axes[1, 0].hist(df['precip_mean'], bins=10, color='blue', alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Precipitation Mean (kg m-2 s-1)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Precipitation Distribution')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Summary table\n",
    "axes[1, 1].axis('off')\n",
    "summary_text = f\"\"\"Climate Analysis Summary\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Total Files: {len(df)}\n",
    "\n",
    "Temperature:\n",
    "  Mean: {df['temp_mean'].mean():.2f} K\n",
    "  Std:  {df['temp_mean'].std():.2f} K\n",
    "\n",
    "Precipitation:\n",
    "  Mean: {df['precip_mean'].mean():.2e}\n",
    "  Total: {df['precip_total'].sum():.2e}\n",
    "\"\"\"\n",
    "\n",
    "axes[1, 1].text(0.1, 0.5, summary_text, fontfamily='monospace', \n",
    "                fontsize=10, verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('climate_analysis_summary.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Figure saved: climate_analysis_summary.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Export Results\n",
    "\n",
    "Save analysis results for archival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('./results')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export DataFrame to CSV\n",
    "csv_file = output_dir / 'analysis_results.csv'\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"✓ CSV exported: {csv_file}\")\n",
    "\n",
    "# Export summary statistics\n",
    "summary = {\n",
    "    'total_files': len(df),\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'temperature': {\n",
    "        'mean': float(df['temp_mean'].mean()),\n",
    "        'std': float(df['temp_mean'].std()),\n",
    "        'min': float(df['temp_min'].min()),\n",
    "        'max': float(df['temp_max'].max())\n",
    "    },\n",
    "    'precipitation': {\n",
    "        'mean': float(df['precip_mean'].mean()),\n",
    "        'std': float(df['precip_mean'].std()),\n",
    "        'total': float(df['precip_total'].sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_file = output_dir / 'summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"✓ Summary exported: {summary_file}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Next Steps\n",
    "\n",
    "What to do next after this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "✓ Analysis Complete!\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "1. REVIEW RESULTS\n",
    "   - Check the figures and CSV output\n",
    "   - Compare statistics across models\n",
    "   - Identify patterns in the data\n",
    "\n",
    "2. EXTEND THE ANALYSIS\n",
    "   - Add more climate variables (e.g., humidity)\n",
    "   - Calculate regional anomalies\n",
    "   - Perform trend analysis\n",
    "\n",
    "3. SHARE RESULTS\n",
    "   - Upload figures to S3 for collaboration\n",
    "   - Generate detailed reports\n",
    "   - Create visualizations for presentations\n",
    "\n",
    "4. CLEAN UP AWS RESOURCES\n",
    "   - Follow cleanup_guide.md\n",
    "   - Delete S3 bucket and Lambda function\n",
    "   - Stop incurring charges\n",
    "\n",
    "5. MOVE TO TIER 3 (OPTIONAL)\n",
    "   - Production-grade CloudFormation templates\n",
    "   - Automated workflows\n",
    "   - Multi-region deployment\n",
    "\n",
    "See README.md for more information!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
