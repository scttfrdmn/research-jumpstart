{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Ensemble Analysis - Studio Lab Quickstart\n",
    "\n",
    "**Project**: Multi-Model Climate Projection Analysis  \n",
    "**Domain**: Climate Science  \n",
    "**Platform**: SageMaker Studio Lab (Free Tier)  \n",
    "\n",
    "## What This Project Does\n",
    "\n",
    "This notebook analyzes multiple climate models to create regional temperature projections. You'll learn how to:\n",
    "\n",
    "- Access climate model data without downloads\n",
    "- Calculate multi-model ensemble statistics\n",
    "- Quantify uncertainty across models\n",
    "- Create publication-quality figures\n",
    "- Work with netCDF climate data\n",
    "\n",
    "## Studio Lab Version Specifications\n",
    "\n",
    "**Data**: 3 CMIP6 models (sample subset)  \n",
    "**Region**: US Southwest  \n",
    "**Variable**: Surface air temperature (tas)  \n",
    "**Scenario**: SSP2-4.5 (moderate emissions)  \n",
    "**Period**: 2015-2050  \n",
    "**Runtime**: ~2-3 hours on CPU  \n",
    "**Storage**: ~500MB  \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic Python knowledge\n",
    "- Understanding of climate models (helpful but not required)\n",
    "- Studio Lab account (free, no AWS account needed)\n",
    "\n",
    "## Ready to Scale?\n",
    "\n",
    "This Studio Lab version uses 3 models and pre-processed data. For production analysis with 20+ models and full CMIP6 access, see the [Unified Studio version](../unified-studio/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Expected: 3.10.x\")\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"\\nâœ… All imports successful!\")\n",
    "print(f\"\\nKey library versions:\")\n",
    "print(f\"  xarray: {xr.__version__}\")\n",
    "print(f\"  numpy: {np.__version__}\")\n",
    "print(f\"  pandas: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration\n",
    "\n",
    "Define analysis parameters. Modify these to explore different regions or time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to analyze (Studio Lab uses 3 for speed)\n",
    "MODELS = [\n",
    "    'CESM2',           # Community Earth System Model 2 (NCAR)\n",
    "    'GFDL-CM4',        # Geophysical Fluid Dynamics Lab CM4\n",
    "    'UKESM1-0-LL'      # UK Earth System Model\n",
    "]\n",
    "\n",
    "# Variable\n",
    "VARIABLE = 'tas'  # Surface air temperature\n",
    "\n",
    "# Scenario\n",
    "SCENARIO = 'ssp245'  # SSP2-4.5: Middle-of-the-road emissions\n",
    "\n",
    "# Time period\n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2050\n",
    "\n",
    "# Region of interest: US Southwest\n",
    "REGION = {\n",
    "    'name': 'US Southwest',\n",
    "    'lat_min': 31.0,\n",
    "    'lat_max': 37.0,\n",
    "    'lon_min': -114.0,\n",
    "    'lon_max': -109.0\n",
    "}\n",
    "\n",
    "# Baseline period for anomalies\n",
    "BASELINE_START = 1995\n",
    "BASELINE_END = 2014\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Models: {', '.join(MODELS)}\")\n",
    "print(f\"  Variable: {VARIABLE} (surface air temperature)\")\n",
    "print(f\"  Scenario: {SCENARIO}\")\n",
    "print(f\"  Analysis period: {START_YEAR}-{END_YEAR}\")\n",
    "print(f\"  Baseline period: {BASELINE_START}-{BASELINE_END}\")\n",
    "print(f\"  Region: {REGION['name']}\")\n",
    "print(f\"    Latitude: {REGION['lat_min']}Â°N to {REGION['lat_max']}Â°N\")\n",
    "print(f\"    Longitude: {REGION['lon_min']}Â°E to {REGION['lon_max']}Â°E\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Access\n",
    "\n",
    "### For Studio Lab: Using Sample Data\n",
    "\n",
    "In this Studio Lab version, we'll simulate climate model data for demonstration purposes. In the production Unified Studio version, you'll access real CMIP6 data directly from S3 without any downloads.\n",
    "\n",
    "**Note**: This demonstrates the workflow with representative data. The actual values are simulated for educational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_climate_data(model_name, region, start_year, end_year, baseline_start, baseline_end):\n",
    "    \"\"\"\n",
    "    Generate sample climate data for demonstration.\n",
    "    \n",
    "    In production (Unified Studio), this would be:\n",
    "    data = xr.open_dataset(f's3://cmip6-pds/CMIP6/.../tas_...{model_name}...nc')\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of climate model\n",
    "        region: Dictionary with lat/lon bounds\n",
    "        start_year: Start year for analysis\n",
    "        end_year: End year for analysis\n",
    "        baseline_start: Baseline start year\n",
    "        baseline_end: Baseline end year\n",
    "    \n",
    "    Returns:\n",
    "        xarray.Dataset with temperature data\n",
    "    \"\"\"\n",
    "    print(f\"  Loading {model_name}...\")\n",
    "    \n",
    "    # Create time coordinate (monthly data)\n",
    "    full_start = baseline_start\n",
    "    full_end = end_year\n",
    "    time = pd.date_range(f'{full_start}-01-01', f'{full_end}-12-31', freq='MS')\n",
    "    \n",
    "    # Create spatial grid (1Â° resolution)\n",
    "    lat = np.arange(region['lat_min'], region['lat_max'], 1.0)\n",
    "    lon = np.arange(region['lon_min'], region['lon_max'], 1.0)\n",
    "    \n",
    "    # Generate realistic temperature data\n",
    "    # Each model has different sensitivity and warming pattern\n",
    "    model_params = {\n",
    "        'CESM2': {'base_temp': 290.0, 'trend': 0.035, 'variability': 2.5},\n",
    "        'GFDL-CM4': {'base_temp': 289.5, 'trend': 0.042, 'variability': 2.8},\n",
    "        'UKESM1-0-LL': {'base_temp': 290.5, 'trend': 0.048, 'variability': 2.2}\n",
    "    }\n",
    "    \n",
    "    params = model_params.get(model_name, model_params['CESM2'])\n",
    "    \n",
    "    # Create temperature array with:\n",
    "    # - Base climatology\n",
    "    # - Linear warming trend\n",
    "    # - Seasonal cycle\n",
    "    # - Interannual variability\n",
    "    n_time = len(time)\n",
    "    n_lat = len(lat)\n",
    "    n_lon = len(lon)\n",
    "    \n",
    "    # Base temperature\n",
    "    tas = np.ones((n_time, n_lat, n_lon)) * params['base_temp']\n",
    "    \n",
    "    # Add latitude gradient (warmer at southern latitudes)\n",
    "    lat_gradient = np.linspace(5, -5, n_lat)\n",
    "    tas += lat_gradient[np.newaxis, :, np.newaxis]\n",
    "    \n",
    "    # Add seasonal cycle\n",
    "    month = np.array([t.month for t in time])\n",
    "    seasonal = 10 * np.sin(2 * np.pi * (month - 1) / 12)\n",
    "    tas += seasonal[:, np.newaxis, np.newaxis]\n",
    "    \n",
    "    # Add warming trend (years since start)\n",
    "    years = np.array([(t.year - full_start) for t in time])\n",
    "    trend = params['trend'] * years / 12  # Convert to monthly\n",
    "    tas += trend[:, np.newaxis, np.newaxis]\n",
    "    \n",
    "    # Add interannual variability\n",
    "    np.random.seed(hash(model_name) % 2**32)  # Reproducible per model\n",
    "    variability = np.random.normal(0, params['variability'], (n_time, n_lat, n_lon))\n",
    "    tas += variability\n",
    "    \n",
    "    # Create xarray Dataset\n",
    "    ds = xr.Dataset({\n",
    "        'tas': (['time', 'lat', 'lon'], tas)\n",
    "    }, coords={\n",
    "        'time': time,\n",
    "        'lat': lat,\n",
    "        'lon': lon\n",
    "    })\n",
    "    \n",
    "    # Add metadata\n",
    "    ds['tas'].attrs = {\n",
    "        'long_name': 'Near-Surface Air Temperature',\n",
    "        'units': 'K',\n",
    "        'standard_name': 'air_temperature',\n",
    "        'model': model_name,\n",
    "        'scenario': SCENARIO\n",
    "    }\n",
    "    \n",
    "    return ds\n",
    "\n",
    "print(\"âœ… Data loading function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load All Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading climate model data...\\n\")\n",
    "\n",
    "# Load data for each model\n",
    "model_data = {}\n",
    "\n",
    "for model in tqdm(MODELS, desc=\"Loading models\"):\n",
    "    ds = generate_sample_climate_data(\n",
    "        model, \n",
    "        REGION, \n",
    "        START_YEAR, \n",
    "        END_YEAR,\n",
    "        BASELINE_START,\n",
    "        BASELINE_END\n",
    "    )\n",
    "    model_data[model] = ds\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(model_data)} models\")\n",
    "print(f\"\\nExample data structure (CESM2):\")\n",
    "print(model_data['CESM2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Processing\n",
    "\n",
    "### Calculate Regional Average Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regional_mean(ds, region):\n",
    "    \"\"\"\n",
    "    Calculate area-weighted regional mean.\n",
    "    \n",
    "    Args:\n",
    "        ds: xarray Dataset with temperature data\n",
    "        region: Dictionary with lat/lon bounds\n",
    "    \n",
    "    Returns:\n",
    "        xarray DataArray with regional mean time series\n",
    "    \"\"\"\n",
    "    # Extract temperature variable\n",
    "    tas = ds['tas']\n",
    "    \n",
    "    # Calculate area weights (cosine of latitude)\n",
    "    weights = np.cos(np.deg2rad(tas.lat))\n",
    "    \n",
    "    # Calculate weighted mean over lat/lon\n",
    "    regional_mean = tas.weighted(weights).mean(['lat', 'lon'])\n",
    "    \n",
    "    return regional_mean\n",
    "\n",
    "print(\"Calculating regional mean time series for each model...\\n\")\n",
    "\n",
    "regional_means = {}\n",
    "for model, ds in tqdm(model_data.items(), desc=\"Processing\"):\n",
    "    regional_means[model] = calculate_regional_mean(ds, REGION)\n",
    "\n",
    "print(\"\\nâœ… Regional means calculated\")\n",
    "print(f\"\\nExample time series shape: {regional_means['CESM2'].shape}\")\n",
    "print(f\"Time range: {regional_means['CESM2'].time.values[0]} to {regional_means['CESM2'].time.values[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Temperature Anomalies\n",
    "\n",
    "Express temperatures as anomalies relative to the baseline period (1995-2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anomaly(time_series, baseline_start, baseline_end):\n",
    "    \"\"\"\n",
    "    Calculate temperature anomaly relative to baseline period.\n",
    "    \n",
    "    Args:\n",
    "        time_series: xarray DataArray with temperature data\n",
    "        baseline_start: Start year of baseline period\n",
    "        baseline_end: End year of baseline period\n",
    "    \n",
    "    Returns:\n",
    "        xarray DataArray with temperature anomalies (K)\n",
    "    \"\"\"\n",
    "    # Select baseline period\n",
    "    baseline = time_series.sel(\n",
    "        time=slice(f'{baseline_start}', f'{baseline_end}')\n",
    "    )\n",
    "    \n",
    "    # Calculate baseline mean\n",
    "    baseline_mean = baseline.mean('time')\n",
    "    \n",
    "    # Calculate anomaly\n",
    "    anomaly = time_series - baseline_mean\n",
    "    \n",
    "    return anomaly\n",
    "\n",
    "print(\"Calculating temperature anomalies...\\n\")\n",
    "\n",
    "anomalies = {}\n",
    "for model, ts in tqdm(regional_means.items(), desc=\"Calculating anomalies\"):\n",
    "    anomalies[model] = calculate_anomaly(ts, BASELINE_START, BASELINE_END)\n",
    "\n",
    "print(\"\\nâœ… Anomalies calculated\")\n",
    "print(f\"\\nBaseline period: {BASELINE_START}-{BASELINE_END}\")\n",
    "print(f\"Baseline mean (CESM2): {regional_means['CESM2'].sel(time=slice(str(BASELINE_START), str(BASELINE_END))).mean().values:.2f} K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Annual Means\n",
    "\n",
    "Smooth monthly data to annual means for easier visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating annual means...\\n\")\n",
    "\n",
    "annual_anomalies = {}\n",
    "for model, anom in tqdm(anomalies.items(), desc=\"Annual means\"):\n",
    "    # Resample to annual means\n",
    "    annual = anom.resample(time='1Y').mean()\n",
    "    annual_anomalies[model] = annual\n",
    "\n",
    "print(\"\\nâœ… Annual means calculated\")\n",
    "print(f\"\\nAnnual data shape: {annual_anomalies['CESM2'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ensemble Statistics\n",
    "\n",
    "Calculate multi-model mean and uncertainty (spread)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating ensemble statistics...\\n\")\n",
    "\n",
    "# Combine all models into single array\n",
    "all_models = xr.concat(\n",
    "    [annual_anomalies[m] for m in MODELS],\n",
    "    dim='model'\n",
    ")\n",
    "all_models['model'] = MODELS\n",
    "\n",
    "# Calculate ensemble mean\n",
    "ensemble_mean = all_models.mean('model')\n",
    "\n",
    "# Calculate ensemble spread (standard deviation)\n",
    "ensemble_std = all_models.std('model')\n",
    "\n",
    "# Calculate min/max range\n",
    "ensemble_min = all_models.min('model')\n",
    "ensemble_max = all_models.max('model')\n",
    "\n",
    "print(\"âœ… Ensemble statistics calculated\")\n",
    "print(f\"\\nEnsemble size: {len(MODELS)} models\")\n",
    "print(f\"\\nProjected warming by 2050 (relative to {BASELINE_START}-{BASELINE_END}):\")\n",
    "\n",
    "# Get 2050 values\n",
    "year_2050 = annual_anomalies['CESM2'].sel(time='2050', method='nearest').time.dt.year.values\n",
    "\n",
    "for model in MODELS:\n",
    "    warming = annual_anomalies[model].sel(time='2050', method='nearest').values\n",
    "    print(f\"  {model}: {warming:.2f}Â°C\")\n",
    "\n",
    "mean_warming = ensemble_mean.sel(time='2050', method='nearest').values\n",
    "std_warming = ensemble_std.sel(time='2050', method='nearest').values\n",
    "\n",
    "print(f\"\\n  Ensemble mean: {mean_warming:.2f}Â°C\")\n",
    "print(f\"  Ensemble spread (Â±1Ïƒ): Â±{std_warming:.2f}Â°C\")\n",
    "print(f\"  Likely range: {mean_warming-std_warming:.2f}Â°C to {mean_warming+std_warming:.2f}Â°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualization\n",
    "\n",
    "### Figure 1: Time Series with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot individual models (thin lines)\n",
    "for model in MODELS:\n",
    "    annual_anomalies[model].plot(\n",
    "        ax=ax, \n",
    "        label=model, \n",
    "        linewidth=1.5, \n",
    "        alpha=0.6\n",
    "    )\n",
    "\n",
    "# Plot ensemble mean (thick line)\n",
    "ensemble_mean.plot(\n",
    "    ax=ax, \n",
    "    label='Ensemble Mean', \n",
    "    color='black', \n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "# Plot uncertainty range (shaded)\n",
    "years = ensemble_mean.time.dt.year.values\n",
    "ax.fill_between(\n",
    "    ensemble_mean.time.values,\n",
    "    (ensemble_mean - ensemble_std).values,\n",
    "    (ensemble_mean + ensemble_std).values,\n",
    "    color='gray',\n",
    "    alpha=0.3,\n",
    "    label='Â±1Ïƒ spread'\n",
    ")\n",
    "\n",
    "# Add zero line\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Year', fontsize=12)\n",
    "ax.set_ylabel('Temperature Anomaly (Â°C)', fontsize=12)\n",
    "ax.set_title(\n",
    "    f'Climate Projections for {REGION[\"name\"]}\\n'\n",
    "    f'SSP2-4.5 Scenario | {len(MODELS)}-Model Ensemble',\n",
    "    fontsize=14,\n",
    "    fontweight='bold'\n",
    ")\n",
    "\n",
    "# Legend\n",
    "ax.legend(loc='upper left', frameon=True, fancybox=True, shadow=True)\n",
    "\n",
    "# Grid\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Figure 1: Time series with uncertainty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: Model Agreement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left panel: Warming rates by decade\n",
    "decades = [\n",
    "    ('2020s', '2020-2029'),\n",
    "    ('2030s', '2030-2039'),\n",
    "    ('2040s', '2040-2049')\n",
    "]\n",
    "\n",
    "decade_warming = {}\n",
    "for decade_name, decade_range in decades:\n",
    "    decade_data = []\n",
    "    for model in MODELS:\n",
    "        decade_mean = annual_anomalies[model].sel(\n",
    "            time=slice(decade_range.split('-')[0], decade_range.split('-')[1])\n",
    "        ).mean().values\n",
    "        decade_data.append(decade_mean)\n",
    "    decade_warming[decade_name] = decade_data\n",
    "\n",
    "# Box plot\n",
    "positions = np.arange(len(decades))\n",
    "bp = ax1.boxplot(\n",
    "    [decade_warming[d[0]] for d in decades],\n",
    "    positions=positions,\n",
    "    widths=0.6,\n",
    "    patch_artist=True,\n",
    "    showmeans=True,\n",
    "    meanprops=dict(marker='D', markerfacecolor='red', markersize=8)\n",
    ")\n",
    "\n",
    "# Color boxes\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax1.set_xticks(positions)\n",
    "ax1.set_xticklabels([d[0] for d in decades])\n",
    "ax1.set_ylabel('Temperature Anomaly (Â°C)', fontsize=11)\n",
    "ax1.set_title('Decadal Mean Warming', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Right panel: Model spread over time\n",
    "ensemble_std.plot(ax=ax2, color='darkred', linewidth=2)\n",
    "ax2.set_xlabel('Year', fontsize=11)\n",
    "ax2.set_ylabel('Inter-Model Std Dev (Â°C)', fontsize=11)\n",
    "ax2.set_title('Model Uncertainty Over Time', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Figure 2: Model agreement analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CLIMATE PROJECTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nRegion: {REGION['name']}\")\n",
    "print(f\"Scenario: {SCENARIO} (SSP2-4.5)\")\n",
    "print(f\"Models: {', '.join(MODELS)}\")\n",
    "print(f\"Baseline period: {BASELINE_START}-{BASELINE_END}\")\n",
    "\n",
    "print(f\"\\n{'Decade':<15} {'Mean Warming (Â°C)':<20} {'Model Range (Â°C)':<25}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for decade_name, decade_range in decades:\n",
    "    start, end = decade_range.split('-')\n",
    "    \n",
    "    # Get decade means for all models\n",
    "    decade_means = []\n",
    "    for model in MODELS:\n",
    "        dm = annual_anomalies[model].sel(\n",
    "            time=slice(start, end)\n",
    "        ).mean().values\n",
    "        decade_means.append(dm)\n",
    "    \n",
    "    mean_val = np.mean(decade_means)\n",
    "    min_val = np.min(decade_means)\n",
    "    max_val = np.max(decade_means)\n",
    "    \n",
    "    print(f\"{decade_name:<15} {mean_val:>7.2f} Â± {np.std(decade_means):4.2f}       {min_val:>6.2f} to {max_val:>5.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "warming_2050 = ensemble_mean.sel(time='2050', method='nearest').values\n",
    "spread_2050 = ensemble_std.sel(time='2050', method='nearest').values\n",
    "\n",
    "print(f\"\\n1. Projected warming by 2050: {warming_2050:.2f}Â°C Â± {spread_2050:.2f}Â°C\")\n",
    "print(f\"   (relative to {BASELINE_START}-{BASELINE_END} baseline)\")\n",
    "\n",
    "# Calculate rate of warming\n",
    "early = ensemble_mean.sel(time=slice('2015', '2025')).mean().values\n",
    "late = ensemble_mean.sel(time=slice('2040', '2050')).mean().values\n",
    "rate = (late - early) / 25  # Per decade\n",
    "\n",
    "print(f\"\\n2. Rate of warming: {rate*10:.2f}Â°C per decade\")\n",
    "\n",
    "# Model agreement\n",
    "agreement = (ensemble_std.sel(time='2050', method='nearest').values / \n",
    "             abs(ensemble_mean.sel(time='2050', method='nearest').values)) * 100\n",
    "\n",
    "print(f\"\\n3. Model uncertainty: {agreement:.1f}% (relative to ensemble mean)\")\n",
    "\n",
    "if agreement < 30:\n",
    "    print(\"   â†’ High confidence (models agree well)\")\n",
    "elif agreement < 50:\n",
    "    print(\"   â†’ Medium confidence (moderate model spread)\")\n",
    "else:\n",
    "    print(\"   â†’ Lower confidence (large model spread)\")\n",
    "\n",
    "print(f\"\\n4. All {len(MODELS)} models project warming in this region\")\n",
    "print(\"   â†’ Robust signal across models\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "### Experiments to Try\n",
    "\n",
    "1. **Change the region**: Modify `REGION` dictionary to analyze a different area\n",
    "2. **Different time period**: Adjust `START_YEAR` and `END_YEAR`\n",
    "3. **Add more visualizations**: Create seasonal analysis, spatial patterns\n",
    "\n",
    "### Ready to Scale?\n",
    "\n",
    "This Studio Lab version uses 3 models and simulated data. For production research:\n",
    "\n",
    "**Unified Studio Version Includes**:\n",
    "- 20+ CMIP6 models (real data from S3)\n",
    "- Full spatial resolution\n",
    "- Multiple scenarios (SSP1-2.6, SSP2-4.5, SSP3-7.0, SSP5-8.5)\n",
    "- Multiple variables (temperature, precipitation, etc.)\n",
    "- Distributed processing with EMR\n",
    "- Bedrock AI for report generation\n",
    "- Publication-quality figures\n",
    "- Statistical significance testing\n",
    "\n",
    "**Cost**: ~$20-30 for full analysis  \n",
    "**Time**: 1-2 days  \n",
    "**Value**: Months of traditional work â†’ Days  \n",
    "\n",
    "[View Unified Studio Version â†’](../unified-studio/)\n",
    "\n",
    "### Learn More\n",
    "\n",
    "- [Transition Guide](../../../../docs/transition-guides/studio-lab-to-unified.md)\n",
    "- [Platform Comparison](../../../../docs/getting-started/platform-comparison.md)\n",
    "- [FAQ](../../../../docs/resources/faq.md)\n",
    "\n",
    "### Contribute\n",
    "\n",
    "Found this useful? Consider:\n",
    "- â­ Star the [GitHub repo](https://github.com/research-jumpstart/research-jumpstart)\n",
    "- ðŸ’¬ Share your experience in [Discussions](https://github.com/research-jumpstart/research-jumpstart/discussions)\n",
    "- ðŸ› Report issues or suggest improvements\n",
    "- ðŸš€ Contribute your own project\n",
    "\n",
    "---\n",
    "\n",
    "**Research Jumpstart** | Built by researchers, for researchers ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
