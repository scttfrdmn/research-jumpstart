{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocean Data Analysis - AWS Tier 2\n",
    "\n",
    "Analyze oceanographic observations stored in AWS DynamoDB.\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Generating sample ocean data\n",
    "2. Uploading to S3 (triggers Lambda processing)\n",
    "3. Querying results from DynamoDB\n",
    "4. Visualizing ocean parameters\n",
    "5. Analyzing marine anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from decimal import Decimal\n",
    "\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Configuration\n",
    "BUCKET_NAME = os.environ.get(\"BUCKET_NAME\", \"ocean-data-YOUR-NAME\")  # Replace with your bucket\n",
    "DYNAMODB_TABLE = os.environ.get(\"DYNAMODB_TABLE\", \"OceanObservations\")\n",
    "AWS_REGION = os.environ.get(\"AWS_REGION\", \"us-east-1\")\n",
    "\n",
    "print(\"AWS Configuration:\")\n",
    "print(f\"  Bucket: {BUCKET_NAME}\")\n",
    "print(f\"  DynamoDB Table: {DYNAMODB_TABLE}\")\n",
    "print(f\"  Region: {AWS_REGION}\")\n",
    "\n",
    "# Initialize AWS clients\n",
    "s3_client = boto3.client(\"s3\", region_name=AWS_REGION)\n",
    "dynamodb = boto3.resource(\"dynamodb\", region_name=AWS_REGION)\n",
    "\n",
    "print(\"\\n✓ AWS clients initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate and Upload Sample Ocean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ocean_data(num_profiles=5, depths=15):\n",
    "    \"\"\"\n",
    "    Generate sample oceanographic data.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    locations = [\n",
    "        {\"name\": \"Gulf Stream\", \"lat\": 40.5, \"lon\": -70.2},\n",
    "        {\"name\": \"Sargasso Sea\", \"lat\": 32.0, \"lon\": -64.0},\n",
    "        {\"name\": \"Labrador Sea\", \"lat\": 58.0, \"lon\": -52.0},\n",
    "        {\"name\": \"Station ALOHA\", \"lat\": 22.75, \"lon\": -158.0},\n",
    "    ]\n",
    "\n",
    "    base_time = datetime.utcnow() - timedelta(days=7)\n",
    "\n",
    "    for i in range(num_profiles):\n",
    "        location = locations[i % len(locations)]\n",
    "        profile_time = base_time + timedelta(days=i)\n",
    "\n",
    "        depth_levels = np.linspace(0, 400, depths)\n",
    "\n",
    "        for depth in depth_levels:\n",
    "            # Temperature profile\n",
    "            surface_temp = 20.0 + np.random.normal(0, 2)\n",
    "            deep_temp = 4.0 + np.random.normal(0, 0.5)\n",
    "            temperature = surface_temp * np.exp(-depth / 100) + deep_temp * (\n",
    "                1 - np.exp(-depth / 100)\n",
    "            )\n",
    "\n",
    "            # Add marine heatwave to Gulf Stream\n",
    "            if location[\"name\"] == \"Gulf Stream\" and depth < 50:\n",
    "                temperature += 3.8\n",
    "\n",
    "            # Salinity profile\n",
    "            salinity = 35.0 + depth / 200 + np.random.normal(0, 0.2)\n",
    "\n",
    "            # pH profile\n",
    "            ph = 8.1 - depth / 1000 + np.random.normal(0, 0.05)\n",
    "            if location[\"name\"] == \"Sargasso Sea\":\n",
    "                ph -= 0.4  # Acidification\n",
    "\n",
    "            # Dissolved oxygen\n",
    "            do = 8.0 * np.exp(-depth / 150) + 2.0 + np.random.normal(0, 0.3)\n",
    "            if location[\"name\"] == \"Station ALOHA\" and 200 < depth < 350:\n",
    "                do = max(1.2, do - 2.5)  # Oxygen minimum zone\n",
    "\n",
    "            # Chlorophyll\n",
    "            chlorophyll = max(0.1, 5.0 * np.exp(-depth / 50) + np.random.normal(0, 0.5))\n",
    "            if location[\"name\"] == \"Labrador Sea\" and depth < 30:\n",
    "                chlorophyll = 28.0  # Spring bloom\n",
    "\n",
    "            data.append(\n",
    "                {\n",
    "                    \"timestamp\": profile_time.isoformat() + \"Z\",\n",
    "                    \"location_name\": location[\"name\"],\n",
    "                    \"latitude\": location[\"lat\"],\n",
    "                    \"longitude\": location[\"lon\"],\n",
    "                    \"depth\": round(depth, 1),\n",
    "                    \"temperature\": round(temperature, 2),\n",
    "                    \"salinity\": round(salinity, 2),\n",
    "                    \"ph\": round(ph, 3),\n",
    "                    \"dissolved_oxygen\": round(max(0.1, do), 2),\n",
    "                    \"chlorophyll\": round(max(0.1, chlorophyll), 2),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Generate sample data\n",
    "df_sample = generate_ocean_data(num_profiles=5, depths=15)\n",
    "print(f\"Generated {len(df_sample)} ocean observations\")\n",
    "print(\"\\nSample data:\")\n",
    "df_sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"ocean_data_{timestamp}.csv\"\n",
    "df_sample.to_csv(csv_filename, index=False)\n",
    "print(f\"Saved to {csv_filename}\")\n",
    "\n",
    "# Upload to S3 (this will trigger Lambda processing)\n",
    "s3_key = f\"raw/{csv_filename}\"\n",
    "print(f\"\\nUploading to S3: s3://{BUCKET_NAME}/{s3_key}\")\n",
    "\n",
    "try:\n",
    "    s3_client.upload_file(csv_filename, BUCKET_NAME, s3_key)\n",
    "    print(\"✓ Upload successful!\")\n",
    "    print(\"\\nLambda function will process this file automatically.\")\n",
    "    print(\"Wait 10-15 seconds for processing to complete...\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Upload failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for Lambda processing\n",
    "import time\n",
    "\n",
    "print(\"Waiting for Lambda processing...\")\n",
    "time.sleep(15)\n",
    "print(\"✓ Processing should be complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Results from DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_dynamodb(table_name, days=7):\n",
    "    \"\"\"\n",
    "    Query all observations from DynamoDB.\n",
    "    \"\"\"\n",
    "    table = dynamodb.Table(table_name)\n",
    "\n",
    "    response = table.scan()\n",
    "    items = response[\"Items\"]\n",
    "\n",
    "    # Continue scanning if there are more items\n",
    "    while \"LastEvaluatedKey\" in response:\n",
    "        response = table.scan(ExclusiveStartKey=response[\"LastEvaluatedKey\"])\n",
    "        items.extend(response[\"Items\"])\n",
    "\n",
    "    # Convert Decimal to float\n",
    "    for item in items:\n",
    "        for key, value in item.items():\n",
    "            if isinstance(value, Decimal):\n",
    "                item[key] = float(value)\n",
    "\n",
    "    return items\n",
    "\n",
    "\n",
    "# Query observations\n",
    "print(\"Querying DynamoDB...\")\n",
    "observations = query_dynamodb(DYNAMODB_TABLE)\n",
    "print(f\"Retrieved {len(observations)} observations\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(observations)\n",
    "\n",
    "if not df.empty:\n",
    "    df = df.sort_values(\"timestamp\")\n",
    "    print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"OCEAN OBSERVATIONS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(f\"\\nTotal Observations: {len(df)}\")\n",
    "\n",
    "    print(\"\\nLocations:\")\n",
    "    for location, count in df[\"location_name\"].value_counts().items():\n",
    "        print(f\"  - {location}: {count}\")\n",
    "\n",
    "    print(\"\\nAnomaly Status:\")\n",
    "    for status, count in df[\"anomaly_status\"].value_counts().items():\n",
    "        print(f\"  - {status}: {count}\")\n",
    "\n",
    "    print(\"\\nParameter Statistics:\")\n",
    "    params = [\"temperature\", \"salinity\", \"ph\", \"dissolved_oxygen\", \"chlorophyll\"]\n",
    "    print(df[params].describe())\n",
    "else:\n",
    "    print(\"No data available yet. Make sure Lambda processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Depth Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # Temperature profile\n",
    "    for location in df[\"location_name\"].unique():\n",
    "        data = df[df[\"location_name\"] == location]\n",
    "        axes[0, 0].plot(data[\"temperature\"], data[\"depth\"], marker=\"o\", label=location)\n",
    "    axes[0, 0].invert_yaxis()\n",
    "    axes[0, 0].set_xlabel(\"Temperature (°C)\")\n",
    "    axes[0, 0].set_ylabel(\"Depth (m)\")\n",
    "    axes[0, 0].set_title(\"Temperature Profiles\")\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Salinity profile\n",
    "    for location in df[\"location_name\"].unique():\n",
    "        data = df[df[\"location_name\"] == location]\n",
    "        axes[0, 1].plot(data[\"salinity\"], data[\"depth\"], marker=\"o\", label=location)\n",
    "    axes[0, 1].invert_yaxis()\n",
    "    axes[0, 1].set_xlabel(\"Salinity (PSU)\")\n",
    "    axes[0, 1].set_ylabel(\"Depth (m)\")\n",
    "    axes[0, 1].set_title(\"Salinity Profiles\")\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Dissolved oxygen profile\n",
    "    for location in df[\"location_name\"].unique():\n",
    "        data = df[df[\"location_name\"] == location]\n",
    "        axes[1, 0].plot(data[\"dissolved_oxygen\"], data[\"depth\"], marker=\"o\", label=location)\n",
    "    axes[1, 0].invert_yaxis()\n",
    "    axes[1, 0].set_xlabel(\"Dissolved Oxygen (mg/L)\")\n",
    "    axes[1, 0].set_ylabel(\"Depth (m)\")\n",
    "    axes[1, 0].set_title(\"Dissolved Oxygen Profiles\")\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Chlorophyll profile\n",
    "    for location in df[\"location_name\"].unique():\n",
    "        data = df[df[\"location_name\"] == location]\n",
    "        axes[1, 1].plot(data[\"chlorophyll\"], data[\"depth\"], marker=\"o\", label=location)\n",
    "    axes[1, 1].invert_yaxis()\n",
    "    axes[1, 1].set_xlabel(\"Chlorophyll-a (mg/m³)\")\n",
    "    axes[1, 1].set_ylabel(\"Depth (m)\")\n",
    "    axes[1, 1].set_title(\"Chlorophyll Profiles\")\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"ocean_depth_profiles.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    print(\"✓ Saved figure: ocean_depth_profiles.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temperature-Salinity (T-S) Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for location in df[\"location_name\"].unique():\n",
    "        data = df[df[\"location_name\"] == location]\n",
    "        plt.scatter(data[\"salinity\"], data[\"temperature\"], label=location, alpha=0.6, s=50)\n",
    "\n",
    "    plt.xlabel(\"Salinity (PSU)\", fontsize=12)\n",
    "    plt.ylabel(\"Temperature (°C)\", fontsize=12)\n",
    "    plt.title(\"Temperature-Salinity Diagram\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"ts_diagram.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    print(\"✓ Saved figure: ts_diagram.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Anomaly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Filter anomalies\n",
    "    anomalies = df[df[\"anomaly_status\"].isin([\"warning\", \"critical\"])]\n",
    "\n",
    "    print(f\"\\nMARINE ANOMALIES DETECTED: {len(anomalies)}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if not anomalies.empty:\n",
    "        for _idx, row in anomalies.iterrows():\n",
    "            print(f\"\\nLocation: {row['location_name']}\")\n",
    "            print(f\"Depth: {row['depth']:.0f}m\")\n",
    "            print(f\"Status: {row['anomaly_status'].upper()}\")\n",
    "            print(f\"Type: {row['anomaly_type']}\")\n",
    "            print(\n",
    "                f\"Temperature: {row['temperature']:.2f}°C (anomaly: {row['temperature_anomaly']:.2f}°C)\"\n",
    "            )\n",
    "            print(f\"pH: {row['ph']:.3f}\")\n",
    "            print(f\"DO: {row['dissolved_oxygen']:.2f} mg/L\")\n",
    "            print(f\"Chlorophyll: {row['chlorophyll']:.2f} mg/m³\")\n",
    "            print(\"-\" * 80)\n",
    "    else:\n",
    "        print(\"No anomalies detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ocean Acidification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # pH vs Depth\n",
    "    for location in df[\"location_name\"].unique():\n",
    "        data = df[df[\"location_name\"] == location]\n",
    "        axes[0].plot(data[\"ph\"], data[\"depth\"], marker=\"o\", label=location)\n",
    "\n",
    "    axes[0].axvline(x=8.1, color=\"green\", linestyle=\"--\", label=\"Normal pH\", alpha=0.5)\n",
    "    axes[0].axvline(x=7.8, color=\"orange\", linestyle=\"--\", label=\"Warning\", alpha=0.5)\n",
    "    axes[0].axvline(x=7.6, color=\"red\", linestyle=\"--\", label=\"Critical\", alpha=0.5)\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_xlabel(\"pH\")\n",
    "    axes[0].set_ylabel(\"Depth (m)\")\n",
    "    axes[0].set_title(\"pH Profile with Thresholds\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Aragonite Saturation\n",
    "    for location in df[\"location_name\"].unique():\n",
    "        data = df[df[\"location_name\"] == location]\n",
    "        axes[1].plot(data[\"aragonite_saturation\"], data[\"depth\"], marker=\"o\", label=location)\n",
    "\n",
    "    axes[1].axvline(x=1.0, color=\"red\", linestyle=\"--\", label=\"Undersaturated\", alpha=0.5)\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_xlabel(\"Aragonite Saturation (Ωarag)\")\n",
    "    axes[1].set_ylabel(\"Depth (m)\")\n",
    "    axes[1].set_title(\"Aragonite Saturation State\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"ocean_acidification.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    print(\"✓ Saved figure: ocean_acidification.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Primary Production Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Surface observations only (< 50m)\n",
    "    surface = df[df[\"depth\"] < 50]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    surface.boxplot(column=\"chlorophyll\", by=\"location_name\", ax=plt.gca())\n",
    "    plt.title(\"Surface Chlorophyll by Location\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"Location\")\n",
    "    plt.ylabel(\"Chlorophyll-a (mg/m³)\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    surface.boxplot(column=\"primary_production\", by=\"location_name\", ax=plt.gca())\n",
    "    plt.title(\"Primary Production by Location\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"Location\")\n",
    "    plt.ylabel(\"Primary Production (mg C/m²/day)\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"primary_production.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    print(\"✓ Saved figure: primary_production.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Export full dataset\n",
    "    export_filename = f\"ocean_observations_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    df.to_csv(export_filename, index=False)\n",
    "    print(f\"✓ Exported {len(df)} observations to {export_filename}\")\n",
    "\n",
    "    # Export anomalies only\n",
    "    if not anomalies.empty:\n",
    "        anomaly_filename = f\"marine_anomalies_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        anomalies.to_csv(anomaly_filename, index=False)\n",
    "        print(f\"✓ Exported {len(anomalies)} anomalies to {anomaly_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- ✓ Generating realistic oceanographic data\n",
    "- ✓ Uploading to S3 (triggering Lambda processing)\n",
    "- ✓ Querying processed results from DynamoDB\n",
    "- ✓ Visualizing ocean depth profiles\n",
    "- ✓ T-S diagram analysis\n",
    "- ✓ Marine anomaly detection (heatwaves, acidification, hypoxia, blooms)\n",
    "- ✓ Ocean acidification metrics\n",
    "- ✓ Primary production analysis\n",
    "\n",
    "### Next Steps:\n",
    "1. Upload your own ocean data\n",
    "2. Modify Lambda thresholds for your region\n",
    "3. Add more parameters (nutrients, currents)\n",
    "4. Implement time series analysis\n",
    "5. Create spatial maps using cartopy\n",
    "6. Move to Tier 3 for production deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
