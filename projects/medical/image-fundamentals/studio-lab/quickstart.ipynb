{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Fundamentals: Chest X-Ray Analysis\n",
    "\n",
    "Learn medical image analysis basics using chest X-ray feature data.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "100 chest X-ray cases (60 Normal, 40 Pneumonia) with extracted features:\n",
    "- **Intensity Features**: Mean, standard deviation\n",
    "- **Texture Features**: Contrast, energy, homogeneity, entropy\n",
    "- **Anatomical Features**: Lung area, heart width ratio, edge density\n",
    "\n",
    "## Methods\n",
    "- Feature distribution analysis\n",
    "- Statistical testing (t-tests)\n",
    "- Classification with traditional ML\n",
    "- ROC curve analysis\n",
    "- Diagnostic performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature data\n",
    "df = pd.read_csv(\"sample_xray_features.csv\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nDiagnosis distribution:\")\n",
    "print(df[\"diagnosis\"].value_counts())\n",
    "print(f\"\\nFeatures: {list(df.columns[2:])}\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by diagnosis\n",
    "feature_cols = [\n",
    "    \"mean_intensity\",\n",
    "    \"std_intensity\",\n",
    "    \"contrast\",\n",
    "    \"energy\",\n",
    "    \"homogeneity\",\n",
    "    \"entropy\",\n",
    "    \"lung_area_percent\",\n",
    "    \"heart_width_ratio\",\n",
    "    \"edge_density\",\n",
    "]\n",
    "\n",
    "print(\"Summary Statistics:\\n\")\n",
    "print(\"Normal Cases:\")\n",
    "print(df[df[\"diagnosis\"] == \"Normal\"][feature_cols].describe().round(2))\n",
    "print(\"\\nPneumonia Cases:\")\n",
    "print(df[df[\"diagnosis\"] == \"Pneumonia\"][feature_cols].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature distributions by diagnosis\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(feature_cols):\n",
    "    # Normal cases\n",
    "    axes[idx].hist(\n",
    "        df[df[\"diagnosis\"] == \"Normal\"][feature],\n",
    "        bins=15,\n",
    "        alpha=0.6,\n",
    "        label=\"Normal\",\n",
    "        color=\"green\",\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "    # Pneumonia cases\n",
    "    axes[idx].hist(\n",
    "        df[df[\"diagnosis\"] == \"Pneumonia\"][feature],\n",
    "        bins=15,\n",
    "        alpha=0.6,\n",
    "        label=\"Pneumonia\",\n",
    "        color=\"red\",\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "\n",
    "    axes[idx].set_xlabel(feature.replace(\"_\", \" \").title(), fontsize=10)\n",
    "    axes[idx].set_ylabel(\"Count\", fontsize=10)\n",
    "    axes[idx].set_title(f\"{feature.replace('_', ' ').title()}\", fontsize=11, fontweight=\"bold\")\n",
    "    axes[idx].legend(fontsize=9)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Note: Pneumonia cases tend to show higher intensity, lower homogeneity, and reduced lung area.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-tests for each feature\n",
    "normal_data = df[df[\"diagnosis\"] == \"Normal\"]\n",
    "pneumonia_data = df[df[\"diagnosis\"] == \"Pneumonia\"]\n",
    "\n",
    "print(\"Statistical Comparison (Independent t-tests):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "for feature in feature_cols:\n",
    "    normal_values = normal_data[feature]\n",
    "    pneumonia_values = pneumonia_data[feature]\n",
    "\n",
    "    t_stat, p_value = stats.ttest_ind(normal_values, pneumonia_values)\n",
    "\n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(\n",
    "        (\n",
    "            (len(normal_values) - 1) * normal_values.std() ** 2\n",
    "            + (len(pneumonia_values) - 1) * pneumonia_values.std() ** 2\n",
    "        )\n",
    "        / (len(normal_values) + len(pneumonia_values) - 2)\n",
    "    )\n",
    "    cohens_d = (normal_values.mean() - pneumonia_values.mean()) / pooled_std\n",
    "\n",
    "    sig = (\n",
    "        \"***\"\n",
    "        if p_value < 0.001\n",
    "        else (\"**\" if p_value < 0.01 else (\"*\" if p_value < 0.05 else \"ns\"))\n",
    "    )\n",
    "\n",
    "    print(f\"{feature:.<30} t={t_stat:.3f}, p={p_value:.4f} {sig}, d={cohens_d:.3f}\")\n",
    "    results.append(\n",
    "        {\"Feature\": feature, \"t-statistic\": t_stat, \"p-value\": p_value, \"Cohen's d\": cohens_d}\n",
    "    )\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Significance: *** p<0.001, ** p<0.01, * p<0.05, ns = not significant\")\n",
    "print(\"Effect size: |d| > 0.8 = large, > 0.5 = medium, > 0.2 = small\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(\"p-value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect sizes\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars = ax.barh(\n",
    "    results_df[\"Feature\"],\n",
    "    np.abs(results_df[\"Cohen's d\"]),\n",
    "    color=[\"green\" if p < 0.05 else \"gray\" for p in results_df[\"p-value\"]],\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "ax.axvline(0.2, color=\"orange\", linestyle=\"--\", linewidth=1, alpha=0.5, label=\"Small effect\")\n",
    "ax.axvline(0.5, color=\"blue\", linestyle=\"--\", linewidth=1, alpha=0.5, label=\"Medium effect\")\n",
    "ax.axvline(0.8, color=\"red\", linestyle=\"--\", linewidth=1, alpha=0.5, label=\"Large effect\")\n",
    "\n",
    "ax.set_xlabel(\"Absolute Effect Size (|Cohen's d|)\", fontsize=12)\n",
    "ax.set_title(\"Feature Discriminative Power\", fontsize=14, fontweight=\"bold\")\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMost Discriminative Features (largest effect sizes):\")\n",
    "print(results_df[[\"Feature\", \"Cohen's d\", \"p-value\"]].head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation matrix\n",
    "correlation = df[feature_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "mask = np.triu(np.ones_like(correlation, dtype=bool), k=1)\n",
    "sns.heatmap(\n",
    "    correlation,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    mask=mask,\n",
    "    square=True,\n",
    "    ax=ax,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    cbar_kws={\"label\": \"Correlation\"},\n",
    ")\n",
    "ax.set_title(\"Feature Correlation Matrix\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHigh Correlations (|r| > 0.7):\")\n",
    "for i in range(len(correlation.columns)):\n",
    "    for j in range(i + 1, len(correlation.columns)):\n",
    "        if abs(correlation.iloc[i, j]) > 0.7:\n",
    "            print(\n",
    "                f\"  {correlation.columns[i]} - {correlation.columns[j]}: r = {correlation.iloc[i, j]:.3f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = df[feature_cols].values\n",
    "y = (df[\"diagnosis\"] == \"Pneumonia\").astype(int).values  # 1 = Pneumonia, 0 = Normal\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(\"\\nClass distribution (training):\")\n",
    "print(f\"  Normal: {(y_train == 0).sum()}\")\n",
    "print(f\"  Pneumonia: {(y_train == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "lr_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "rf_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Model Training Complete\")\n",
    "print(f\"\\nLogistic Regression - Training Accuracy: {lr_model.score(X_train_scaled, y_train):.3f}\")\n",
    "print(f\"Logistic Regression - Test Accuracy: {lr_model.score(X_test_scaled, y_test):.3f}\")\n",
    "print(f\"\\nRandom Forest - Training Accuracy: {rf_model.score(X_train_scaled, y_train):.3f}\")\n",
    "print(f\"Random Forest - Test Accuracy: {rf_model.score(X_test_scaled, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "lr_cm = confusion_matrix(y_test, lr_pred)\n",
    "rf_cm = confusion_matrix(y_test, rf_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Logistic Regression confusion matrix\n",
    "sns.heatmap(\n",
    "    lr_cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    ax=axes[0],\n",
    "    xticklabels=[\"Normal\", \"Pneumonia\"],\n",
    "    yticklabels=[\"Normal\", \"Pneumonia\"],\n",
    ")\n",
    "axes[0].set_xlabel(\"Predicted\", fontsize=11)\n",
    "axes[0].set_ylabel(\"Actual\", fontsize=11)\n",
    "axes[0].set_title(\"Logistic Regression - Confusion Matrix\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Random Forest confusion matrix\n",
    "sns.heatmap(\n",
    "    rf_cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Greens\",\n",
    "    ax=axes[1],\n",
    "    xticklabels=[\"Normal\", \"Pneumonia\"],\n",
    "    yticklabels=[\"Normal\", \"Pneumonia\"],\n",
    ")\n",
    "axes[1].set_xlabel(\"Predicted\", fontsize=11)\n",
    "axes[1].set_ylabel(\"Actual\", fontsize=11)\n",
    "axes[1].set_title(\"Random Forest - Confusion Matrix\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, lr_pred, target_names=[\"Normal\", \"Pneumonia\"]))\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, rf_pred, target_names=[\"Normal\", \"Pneumonia\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ROC Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curves\n",
    "lr_fpr, lr_tpr, lr_thresholds = roc_curve(y_test, lr_proba)\n",
    "lr_auc = auc(lr_fpr, lr_tpr)\n",
    "\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, rf_proba)\n",
    "rf_auc = auc(rf_fpr, rf_tpr)\n",
    "\n",
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.plot(\n",
    "    lr_fpr, lr_tpr, linewidth=2, label=f\"Logistic Regression (AUC = {lr_auc:.3f})\", color=\"blue\"\n",
    ")\n",
    "ax.plot(rf_fpr, rf_tpr, linewidth=2, label=f\"Random Forest (AUC = {rf_auc:.3f})\", color=\"green\")\n",
    "ax.plot([0, 1], [0, 1], \"k--\", linewidth=1, label=\"Random Classifier (AUC = 0.500)\")\n",
    "\n",
    "ax.set_xlabel(\"False Positive Rate\", fontsize=12)\n",
    "ax.set_ylabel(\"True Positive Rate (Sensitivity)\", fontsize=12)\n",
    "ax.set_title(\"ROC Curves - Pneumonia Detection\", fontsize=14, fontweight=\"bold\")\n",
    "ax.legend(fontsize=11, loc=\"lower right\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC-AUC Interpretation:\")\n",
    "print(f\"  Logistic Regression AUC: {lr_auc:.3f}\")\n",
    "print(f\"  Random Forest AUC: {rf_auc:.3f}\")\n",
    "print(\"\\n  0.90-1.00: Excellent\")\n",
    "print(\"  0.80-0.90: Good\")\n",
    "print(\"  0.70-0.80: Fair\")\n",
    "print(\"  0.60-0.70: Poor\")\n",
    "print(\"  0.50-0.60: Fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": feature_cols, \"Importance\": importances}\n",
    ").sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = ax.barh(\n",
    "    feature_importance_df[\"Feature\"],\n",
    "    feature_importance_df[\"Importance\"],\n",
    "    color=\"forestgreen\",\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "ax.set_xlabel(\"Feature Importance\", fontsize=12)\n",
    "ax.set_title(\"Random Forest Feature Importance\", fontsize=14, fontweight=\"bold\")\n",
    "ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop Features for Pneumonia Detection:\")\n",
    "print(feature_importance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Clinical Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic performance metrics\n",
    "def calculate_metrics(cm):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp)  # Positive Predictive Value\n",
    "    npv = tn / (tn + fn)  # Negative Predictive Value\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return sensitivity, specificity, ppv, npv, accuracy\n",
    "\n",
    "\n",
    "lr_sens, lr_spec, lr_ppv, lr_npv, lr_acc = calculate_metrics(lr_cm)\n",
    "rf_sens, rf_spec, rf_ppv, rf_npv, rf_acc = calculate_metrics(rf_cm)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DIAGNOSTIC PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(\n",
    "    f\"  Sensitivity (Recall): {lr_sens:.3f} - Correctly identifies {lr_sens * 100:.1f}% of pneumonia cases\"\n",
    ")\n",
    "print(\n",
    "    f\"  Specificity:          {lr_spec:.3f} - Correctly identifies {lr_spec * 100:.1f}% of normal cases\"\n",
    ")\n",
    "print(\n",
    "    f\"  PPV (Precision):      {lr_ppv:.3f} - {lr_ppv * 100:.1f}% of positive predictions are correct\"\n",
    ")\n",
    "print(\n",
    "    f\"  NPV:                  {lr_npv:.3f} - {lr_npv * 100:.1f}% of negative predictions are correct\"\n",
    ")\n",
    "print(f\"  Accuracy:             {lr_acc:.3f}\")\n",
    "print(f\"  AUC:                  {lr_auc:.3f}\")\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(\n",
    "    f\"  Sensitivity (Recall): {rf_sens:.3f} - Correctly identifies {rf_sens * 100:.1f}% of pneumonia cases\"\n",
    ")\n",
    "print(\n",
    "    f\"  Specificity:          {rf_spec:.3f} - Correctly identifies {rf_spec * 100:.1f}% of normal cases\"\n",
    ")\n",
    "print(\n",
    "    f\"  PPV (Precision):      {rf_ppv:.3f} - {rf_ppv * 100:.1f}% of positive predictions are correct\"\n",
    ")\n",
    "print(\n",
    "    f\"  NPV:                  {rf_npv:.3f} - {rf_npv * 100:.1f}% of negative predictions are correct\"\n",
    ")\n",
    "print(f\"  Accuracy:             {rf_acc:.3f}\")\n",
    "print(f\"  AUC:                  {rf_auc:.3f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nClinical Interpretation:\")\n",
    "print(\"  - High sensitivity is crucial to avoid missing pneumonia cases\")\n",
    "print(\"  - High specificity reduces unnecessary treatment of normal cases\")\n",
    "print(\"  - PPV indicates how confident we can be in positive diagnoses\")\n",
    "print(\"  - NPV indicates how confident we can be in negative diagnoses\")\n",
    "print(\"  - AUC > 0.8 suggests good discriminative ability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts Learned\n",
    "\n",
    "### Medical Image Features\n",
    "- **Intensity**: Brightness patterns in X-rays\n",
    "- **Texture**: Spatial patterns (homogeneity, entropy)\n",
    "- **Anatomical**: Organ measurements and proportions\n",
    "\n",
    "### Statistical Testing\n",
    "- **t-tests**: Compare features between groups\n",
    "- **Effect Size**: Magnitude of difference (Cohen's d)\n",
    "- **p-values**: Statistical significance\n",
    "\n",
    "### Classification Performance\n",
    "- **Sensitivity**: True positive rate (recall)\n",
    "- **Specificity**: True negative rate\n",
    "- **PPV**: Positive predictive value (precision)\n",
    "- **NPV**: Negative predictive value\n",
    "- **AUC**: Overall discriminative ability\n",
    "\n",
    "### ROC Curves\n",
    "- Trade-off between sensitivity and specificity\n",
    "- Threshold selection for clinical application\n",
    "- AUC as single performance metric\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Extend the Analysis\n",
    "- Add more features (shape descriptors, wavelet features)\n",
    "- Try deep learning (CNNs on actual images)\n",
    "- Multi-class classification (multiple diseases)\n",
    "- Ensemble methods\n",
    "\n",
    "### Real Medical Images\n",
    "- **[NIH Chest X-Ray Dataset](https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community)**: 100,000+ images\n",
    "- **[MIMIC-CXR](https://physionet.org/content/mimic-cxr/2.0.0/)**: 377,000+ images with reports\n",
    "- **[CheXpert](https://stanfordmlgroup.github.io/competitions/chexpert/)**: 224,000+ chest radiographs\n",
    "\n",
    "### Advanced Methods\n",
    "- Convolutional Neural Networks (ResNet, DenseNet)\n",
    "- Transfer learning from ImageNet\n",
    "- Attention mechanisms\n",
    "- Explainability (GradCAM, SHAP)\n",
    "- Multi-task learning\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **[RadioGraphics](https://pubs.rsna.org/journal/radiographics)**: Radiology journal\n",
    "- **[Grand Challenge](https://grand-challenge.org/)**: Medical imaging competitions\n",
    "- **[PyRadiomics](https://pyradiomics.readthedocs.io/)**: Feature extraction library\n",
    "- **Textbook**: *Medical Image Analysis* by Atam Dhawan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
