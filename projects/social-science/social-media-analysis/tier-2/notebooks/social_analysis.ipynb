{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media Sentiment Analysis - AWS Tier 2\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Downloading sample social media data\n",
    "2. Uploading to S3\n",
    "3. Querying sentiment results from DynamoDB\n",
    "4. Visualizing sentiment trends\n",
    "5. Network analysis of user interactions\n",
    "6. Hashtag co-occurrence analysis\n",
    "\n",
    "**Duration:** 30-45 minutes  \n",
    "**Cost:** $6-10 (includes AWS Comprehend API calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Configuration\n",
    "AWS_REGION = 'us-east-1'\n",
    "BUCKET_NAME = 'social-media-data-XXXX'  # Replace with your bucket name\n",
    "DYNAMODB_TABLE = 'SocialMediaPosts'\n",
    "\n",
    "# Initialize AWS clients\n",
    "s3_client = boto3.client('s3', region_name=AWS_REGION)\n",
    "dynamodb = boto3.resource('dynamodb', region_name=AWS_REGION)\n",
    "table = dynamodb.Table(DYNAMODB_TABLE)\n",
    "\n",
    "print(f\"AWS clients initialized for region: {AWS_REGION}\")\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"DynamoDB Table: {DYNAMODB_TABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Sample Data\n",
    "\n",
    "Generate sample social media posts for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample posts\n",
    "sample_posts = [\n",
    "    {\n",
    "        \"post_id\": \"001\",\n",
    "        \"text\": \"Just finished an amazing research project on climate change! Excited to share results soon. #research #climate #science\",\n",
    "        \"timestamp\": int(datetime.now().timestamp()) - 86400,\n",
    "        \"user_id\": \"user001\",\n",
    "        \"username\": \"researcher_jane\"\n",
    "    },\n",
    "    {\n",
    "        \"post_id\": \"002\",\n",
    "        \"text\": \"Disappointed with the lack of funding for social science research. We need more support! #funding #socialscience\",\n",
    "        \"timestamp\": int(datetime.now().timestamp()) - 82800,\n",
    "        \"user_id\": \"user002\",\n",
    "        \"username\": \"prof_smith\"\n",
    "    },\n",
    "    {\n",
    "        \"post_id\": \"003\",\n",
    "        \"text\": \"Great collaboration with @researcher_jane today! Looking forward to our next meeting. #collaboration\",\n",
    "        \"timestamp\": int(datetime.now().timestamp()) - 79200,\n",
    "        \"user_id\": \"user003\",\n",
    "        \"username\": \"dr_anderson\"\n",
    "    },\n",
    "    {\n",
    "        \"post_id\": \"004\",\n",
    "        \"text\": \"New paper published! Check out our findings on social media sentiment analysis. Link in bio. #publication #research\",\n",
    "        \"timestamp\": int(datetime.now().timestamp()) - 75600,\n",
    "        \"user_id\": \"user001\",\n",
    "        \"username\": \"researcher_jane\"\n",
    "    },\n",
    "    {\n",
    "        \"post_id\": \"005\",\n",
    "        \"text\": \"Frustrated with the peer review process. Why does it take so long? #academia #peerreview\",\n",
    "        \"timestamp\": int(datetime.now().timestamp()) - 72000,\n",
    "        \"user_id\": \"user004\",\n",
    "        \"username\": \"grad_student\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Save to JSON file\n",
    "with open('sample_posts.json', 'w') as f:\n",
    "    json.dump(sample_posts, f, indent=2)\n",
    "\n",
    "print(f\"Created {len(sample_posts)} sample posts\")\n",
    "print(\"\\nFirst post example:\")\n",
    "print(json.dumps(sample_posts[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Data to S3\n",
    "\n",
    "Upload sample posts to S3, which will trigger Lambda processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "s3_key = 'raw/sample_posts.json'\n",
    "\n",
    "with open('sample_posts.json', 'r') as f:\n",
    "    s3_client.put_object(\n",
    "        Bucket=BUCKET_NAME,\n",
    "        Key=s3_key,\n",
    "        Body=f.read(),\n",
    "        ContentType='application/json'\n",
    "    )\n",
    "\n",
    "print(f\"Uploaded sample posts to s3://{BUCKET_NAME}/{s3_key}\")\n",
    "print(\"\\nLambda function should automatically process these posts.\")\n",
    "print(\"Wait 10-30 seconds for processing to complete...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for processing\n",
    "import time\n",
    "print(\"Waiting for Lambda processing...\")\n",
    "for i in range(10, 0, -1):\n",
    "    print(f\"{i}...\", end=' ', flush=True)\n",
    "    time.sleep(1)\n",
    "print(\"\\nDone! Now querying results...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Results from DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query all posts from DynamoDB\n",
    "response = table.scan(Limit=100)\n",
    "items = response.get('Items', [])\n",
    "\n",
    "print(f\"Retrieved {len(items)} posts from DynamoDB\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(items)\n",
    "print(\"\\nDataFrame shape:\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "print(\"\\nSentiment Scores Summary:\")\n",
    "print(df[['positive_score', 'negative_score', 'neutral_score']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "axes[0].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%')\n",
    "axes[0].set_title('Sentiment Distribution')\n",
    "\n",
    "# Bar chart\n",
    "sentiment_counts.plot(kind='bar', ax=axes[1], color=['green', 'red', 'blue', 'orange'])\n",
    "axes[1].set_title('Sentiment Counts')\n",
    "axes[1].set_xlabel('Sentiment')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(df['positive_score'], bins=20, color='green', alpha=0.7)\n",
    "axes[0].set_title('Positive Score Distribution')\n",
    "axes[0].set_xlabel('Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].hist(df['negative_score'], bins=20, color='red', alpha=0.7)\n",
    "axes[1].set_title('Negative Score Distribution')\n",
    "axes[1].set_xlabel('Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "axes[2].hist(df['neutral_score'], bins=20, color='blue', alpha=0.7)\n",
    "axes[2].set_title('Neutral Score Distribution')\n",
    "axes[2].set_xlabel('Score')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hashtag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all hashtags\n",
    "all_hashtags = []\n",
    "for hashtags in df['hashtags']:\n",
    "    if isinstance(hashtags, list):\n",
    "        all_hashtags.extend(hashtags)\n",
    "\n",
    "hashtag_counts = Counter(all_hashtags)\n",
    "print(\"Top 10 Hashtags:\")\n",
    "for hashtag, count in hashtag_counts.most_common(10):\n",
    "    print(f\"  #{hashtag}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top hashtags\n",
    "top_hashtags = dict(hashtag_counts.most_common(10))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(top_hashtags)), list(top_hashtags.values()))\n",
    "plt.xticks(range(len(top_hashtags)), [f'#{h}' for h in top_hashtags.keys()], rotation=45, ha='right')\n",
    "plt.xlabel('Hashtag')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 10 Hashtags')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashtag sentiment correlation\n",
    "hashtag_sentiment = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if isinstance(row['hashtags'], list):\n",
    "        for hashtag in row['hashtags']:\n",
    "            if hashtag not in hashtag_sentiment:\n",
    "                hashtag_sentiment[hashtag] = []\n",
    "            hashtag_sentiment[hashtag].append(row['positive_score'])\n",
    "\n",
    "# Calculate average positive score per hashtag\n",
    "hashtag_avg_sentiment = {h: np.mean(scores) for h, scores in hashtag_sentiment.items() if len(scores) > 0}\n",
    "\n",
    "print(\"\\nHashtag Average Positive Sentiment:\")\n",
    "for hashtag, avg_score in sorted(hashtag_avg_sentiment.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"  #{hashtag}: {avg_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. User Mention Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mention network\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    username = row.get('username', 'unknown')\n",
    "    mentions = row.get('mentions', [])\n",
    "    \n",
    "    # Add nodes\n",
    "    G.add_node(username)\n",
    "    \n",
    "    # Add edges for mentions\n",
    "    if isinstance(mentions, list):\n",
    "        for mention in mentions:\n",
    "            G.add_edge(username, mention)\n",
    "\n",
    "print(f\"Network statistics:\")\n",
    "print(f\"  Nodes (users): {G.number_of_nodes()}\")\n",
    "print(f\"  Edges (mentions): {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize network\n",
    "if G.number_of_nodes() > 0:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Calculate node sizes based on degree\n",
    "    degrees = dict(G.degree())\n",
    "    node_sizes = [300 + degrees[node] * 200 for node in G.nodes()]\n",
    "    \n",
    "    # Layout\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "    \n",
    "    # Draw network\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='lightblue', alpha=0.7)\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.5, arrows=True, arrowsize=20)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "    \n",
    "    plt.title('User Mention Network')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No mention network found in data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network centrality measures\n",
    "if G.number_of_nodes() > 0:\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    \n",
    "    print(\"\\nMost central users (by degree):\")\n",
    "    for user, centrality in sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "        print(f\"  @{user}: {centrality:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Temporal Analysis (if timestamps available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps to datetime\n",
    "if 'timestamp' in df.columns:\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    df = df.sort_values('datetime')\n",
    "    \n",
    "    print(\"Time range of posts:\")\n",
    "    print(f\"  Earliest: {df['datetime'].min()}\")\n",
    "    print(f\"  Latest: {df['datetime'].max()}\")\n",
    "    \n",
    "    # Plot sentiment over time\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    for sentiment in ['POSITIVE', 'NEGATIVE', 'NEUTRAL']:\n",
    "        sentiment_df = df[df['sentiment'] == sentiment]\n",
    "        plt.plot(sentiment_df['datetime'], sentiment_df['positive_score'], \n",
    "                marker='o', label=sentiment, alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Positive Score')\n",
    "    plt.title('Sentiment Scores Over Time')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Timestamp column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SOCIAL MEDIA SENTIMENT ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal posts analyzed: {len(df)}\")\n",
    "print(f\"\\nSentiment Distribution:\")\n",
    "for sentiment, count in df['sentiment'].value_counts().items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {sentiment}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nAverage Sentiment Scores:\")\n",
    "print(f\"  Positive: {df['positive_score'].mean():.3f}\")\n",
    "print(f\"  Negative: {df['negative_score'].mean():.3f}\")\n",
    "print(f\"  Neutral: {df['neutral_score'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nTop 5 Hashtags:\")\n",
    "for hashtag, count in hashtag_counts.most_common(5):\n",
    "    print(f\"  #{hashtag}: {count}\")\n",
    "\n",
    "print(f\"\\nNetwork Statistics:\")\n",
    "print(f\"  Users: {G.number_of_nodes()}\")\n",
    "print(f\"  Mentions: {G.number_of_edges()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df.to_csv('sentiment_results.csv', index=False)\n",
    "print(\"Results exported to sentiment_results.csv\")\n",
    "\n",
    "# Export summary statistics\n",
    "summary = {\n",
    "    'total_posts': len(df),\n",
    "    'sentiment_distribution': df['sentiment'].value_counts().to_dict(),\n",
    "    'average_scores': {\n",
    "        'positive': float(df['positive_score'].mean()),\n",
    "        'negative': float(df['negative_score'].mean()),\n",
    "        'neutral': float(df['neutral_score'].mean())\n",
    "    },\n",
    "    'top_hashtags': dict(hashtag_counts.most_common(10))\n",
    "}\n",
    "\n",
    "with open('sentiment_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Summary exported to sentiment_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Upload more data**: Try uploading larger datasets (100+ posts)\n",
    "2. **Real data**: Use Twitter API or other sources for real social media data\n",
    "3. **Advanced analysis**: Topic modeling, emotion detection, trend analysis\n",
    "4. **Athena queries**: Query exported data in S3 using SQL\n",
    "5. **Dashboard**: Create interactive dashboard with QuickSight\n",
    "6. **Cleanup**: Don't forget to delete AWS resources when done (see cleanup_guide.md)\n",
    "\n",
    "**Remember to clean up AWS resources to avoid charges!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
