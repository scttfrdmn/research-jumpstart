{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: VADER vs AWS Comprehend\n",
    "\n",
    "This notebook compares two approaches to sentiment analysis:\n",
    "1. **VADER** (Valence Aware Dictionary and sEntiment Reasoner) - Free, local analysis\n",
    "2. **AWS Comprehend** - Managed ML service, pay-per-use\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Load and preprocess social media data\n",
    "2. Perform sentiment analysis with VADER\n",
    "3. Perform sentiment analysis with AWS Comprehend\n",
    "4. Compare results and accuracy\n",
    "5. Visualize sentiment distributions\n",
    "6. Analyze sentiment trends over time\n",
    "\n",
    "## When to Use Each Approach\n",
    "\n",
    "**VADER**:\n",
    "- ✅ Free (no API costs)\n",
    "- ✅ Fast for large datasets\n",
    "- ✅ Optimized for social media text\n",
    "- ⚠️ Less accurate on complex sentiment\n",
    "- ⚠️ English-only\n",
    "\n",
    "**AWS Comprehend**:\n",
    "- ✅ Higher accuracy (deep learning-based)\n",
    "- ✅ Multi-language support (100+ languages)\n",
    "- ✅ Confidence scores for each sentiment\n",
    "- ⚠️ Costs ~$0.0001 per 100 characters\n",
    "- ⚠️ API rate limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "\n",
    "from social_media_analysis import ComprehendAnalyzer, preprocess_text\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "load_dotenv(Path(\"..\") / \".env\")\n",
    "\n",
    "DATA_BUCKET = os.getenv(\"DATA_BUCKET\")\n",
    "RESULTS_BUCKET = os.getenv(\"RESULTS_BUCKET\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "USE_COMPREHEND = os.getenv(\"USE_COMPREHEND\", \"false\").lower() == \"true\"\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Data Bucket: {DATA_BUCKET}\")\n",
    "print(f\"  Use Comprehend: {USE_COMPREHEND}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "df = pd.read_csv(\"../../studio-lab/sample_data.csv\")\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "print(f\"Loaded {len(df)} posts\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "df[\"clean_text\"] = df[\"text\"].apply(lambda x: preprocess_text(x, remove_stopwords=False))\n",
    "\n",
    "# Show example\n",
    "print(\"Original vs Cleaned Text:\")\n",
    "for idx in range(3):\n",
    "    print(f\"\\n{idx + 1}. Original:\")\n",
    "    print(f\"   {df.iloc[idx]['text']}\")\n",
    "    print(\"   Cleaned:\")\n",
    "    print(f\"   {df.iloc[idx]['clean_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# Analyze sentiment\n",
    "def vader_sentiment(text):\n",
    "    scores = vader.polarity_scores(text)\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"vader_compound\": scores[\"compound\"],\n",
    "            \"vader_pos\": scores[\"pos\"],\n",
    "            \"vader_neu\": scores[\"neu\"],\n",
    "            \"vader_neg\": scores[\"neg\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Running VADER sentiment analysis...\")\n",
    "vader_scores = df[\"text\"].apply(vader_sentiment)\n",
    "df = pd.concat([df, vader_scores], axis=1)\n",
    "\n",
    "\n",
    "# Classify sentiment based on compound score\n",
    "def classify_vader(compound):\n",
    "    if compound >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif compound <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "\n",
    "df[\"vader_sentiment\"] = df[\"vader_compound\"].apply(classify_vader)\n",
    "\n",
    "print(\"✓ VADER analysis complete\")\n",
    "print(\"\\nVADER Sentiment Distribution:\")\n",
    "print(df[\"vader_sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize VADER results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Sentiment distribution\n",
    "df[\"vader_sentiment\"].value_counts().plot(kind=\"bar\", ax=axes[0], color=\"steelblue\")\n",
    "axes[0].set_title(\"VADER Sentiment Distribution\")\n",
    "axes[0].set_xlabel(\"Sentiment\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Compound score distribution\n",
    "axes[1].hist(df[\"vader_compound\"], bins=20, color=\"coral\", edgecolor=\"black\")\n",
    "axes[1].set_title(\"VADER Compound Score Distribution\")\n",
    "axes[1].set_xlabel(\"Compound Score\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "axes[1].axvline(0, color=\"red\", linestyle=\"--\", label=\"Neutral threshold\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AWS Comprehend Sentiment Analysis\n",
    "\n",
    "**Note**: This will incur AWS costs (~$0.0001 per 100 characters). Set `USE_COMPREHEND=false` in `.env` to skip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_COMPREHEND:\n",
    "    # Initialize Comprehend client\n",
    "    comprehend = ComprehendAnalyzer(region=AWS_REGION)\n",
    "\n",
    "    def analyze_with_comprehend(text):\n",
    "        try:\n",
    "            result = comprehend.analyze_sentiment(text[:5000])  # Comprehend limit\n",
    "            return pd.Series(\n",
    "                {\n",
    "                    \"comprehend_sentiment\": result[\"Sentiment\"].lower(),\n",
    "                    \"comprehend_positive\": result[\"SentimentScore\"][\"Positive\"],\n",
    "                    \"comprehend_negative\": result[\"SentimentScore\"][\"Negative\"],\n",
    "                    \"comprehend_neutral\": result[\"SentimentScore\"][\"Neutral\"],\n",
    "                    \"comprehend_mixed\": result[\"SentimentScore\"][\"Mixed\"],\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return pd.Series(\n",
    "                {\n",
    "                    \"comprehend_sentiment\": \"error\",\n",
    "                    \"comprehend_positive\": 0,\n",
    "                    \"comprehend_negative\": 0,\n",
    "                    \"comprehend_neutral\": 0,\n",
    "                    \"comprehend_mixed\": 0,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    print(\"Running AWS Comprehend sentiment analysis...\")\n",
    "    print(f\"Estimated cost: ${len(df) * df['text'].str.len().mean() / 100 * 0.0001:.4f}\")\n",
    "\n",
    "    # Process with progress bar\n",
    "    tqdm.pandas(desc=\"Comprehend\")\n",
    "    comprehend_scores = df[\"text\"].progress_apply(analyze_with_comprehend)\n",
    "    df = pd.concat([df, comprehend_scores], axis=1)\n",
    "\n",
    "    print(\"✓ Comprehend analysis complete\")\n",
    "    print(\"\\nComprehend Sentiment Distribution:\")\n",
    "    print(df[\"comprehend_sentiment\"].value_counts())\n",
    "else:\n",
    "    print(\"⚠️ Comprehend disabled. Set USE_COMPREHEND=true in .env to enable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_COMPREHEND:\n",
    "    # Visualize Comprehend results\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Sentiment distribution\n",
    "    df[\"comprehend_sentiment\"].value_counts().plot(kind=\"bar\", ax=axes[0], color=\"teal\")\n",
    "    axes[0].set_title(\"Comprehend Sentiment Distribution\")\n",
    "    axes[0].set_xlabel(\"Sentiment\")\n",
    "    axes[0].set_ylabel(\"Count\")\n",
    "    axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Confidence scores\n",
    "    score_cols = [\n",
    "        \"comprehend_positive\",\n",
    "        \"comprehend_negative\",\n",
    "        \"comprehend_neutral\",\n",
    "        \"comprehend_mixed\",\n",
    "    ]\n",
    "    df[score_cols].mean().plot(kind=\"bar\", ax=axes[1], color=\"salmon\")\n",
    "    axes[1].set_title(\"Average Comprehend Confidence Scores\")\n",
    "    axes[1].set_xlabel(\"Sentiment Type\")\n",
    "    axes[1].set_ylabel(\"Average Confidence\")\n",
    "    axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare VADER vs Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_COMPREHEND:\n",
    "    # Comparison matrix\n",
    "    comparison = pd.crosstab(\n",
    "        df[\"vader_sentiment\"],\n",
    "        df[\"comprehend_sentiment\"],\n",
    "        rownames=[\"VADER\"],\n",
    "        colnames=[\"Comprehend\"],\n",
    "    )\n",
    "\n",
    "    print(\"Sentiment Agreement Matrix:\")\n",
    "    print(comparison)\n",
    "\n",
    "    # Calculate agreement percentage\n",
    "    agreement = (df[\"vader_sentiment\"] == df[\"comprehend_sentiment\"]).sum()\n",
    "    agreement_pct = (agreement / len(df)) * 100\n",
    "\n",
    "    print(f\"\\nAgreement: {agreement}/{len(df)} ({agreement_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_COMPREHEND:\n",
    "    # Visualize comparison\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(comparison, annot=True, fmt=\"d\", cmap=\"YlOrRd\", ax=ax, cbar_kws={\"label\": \"Count\"})\n",
    "    ax.set_title(\"VADER vs Comprehend Agreement Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_COMPREHEND:\n",
    "    # Analyze disagreements\n",
    "    disagreements = df[df[\"vader_sentiment\"] != df[\"comprehend_sentiment\"]]\n",
    "\n",
    "    print(f\"Found {len(disagreements)} disagreements ({len(disagreements) / len(df) * 100:.1f}%)\")\n",
    "    print(\"\\nExample disagreements:\")\n",
    "\n",
    "    for idx, row in disagreements.head(5).iterrows():\n",
    "        print(f\"\\nText: {row['text'][:100]}...\")\n",
    "        print(f\"VADER: {row['vader_sentiment']} (compound: {row['vader_compound']:.3f})\")\n",
    "        print(\n",
    "            f\"Comprehend: {row['comprehend_sentiment']} \"\n",
    "            f\"(confidence: {row[f'comprehend_{row[\"comprehend_sentiment\"]}']:.3f})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sentiment Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment trend using VADER\n",
    "df[\"date\"] = df[\"timestamp\"].dt.date\n",
    "daily_sentiment = df.groupby([\"date\", \"vader_sentiment\"]).size().unstack(fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "daily_sentiment.plot(kind=\"bar\", stacked=True, ax=ax, color=[\"#d62728\", \"#7f7f7f\", \"#2ca02c\"])\n",
    "ax.set_title(\"Sentiment Distribution Over Time (VADER)\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Number of Posts\")\n",
    "ax.legend(title=\"Sentiment\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average compound score over time\n",
    "avg_compound = df.groupby(\"date\")[\"vader_compound\"].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "avg_compound.plot(kind=\"line\", marker=\"o\", ax=ax, color=\"purple\", linewidth=2)\n",
    "ax.axhline(0, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Neutral\")\n",
    "ax.fill_between(avg_compound.index, avg_compound.values, 0, alpha=0.3, color=\"purple\")\n",
    "ax.set_title(\"Average Sentiment Score Over Time\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Average Compound Score\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sentiment by Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform comparison\n",
    "platform_sentiment = pd.crosstab(df[\"platform\"], df[\"vader_sentiment\"], normalize=\"index\") * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "platform_sentiment.plot(kind=\"bar\", ax=ax, color=[\"#d62728\", \"#7f7f7f\", \"#2ca02c\"])\n",
    "ax.set_title(\"Sentiment Distribution by Platform (%)\")\n",
    "ax.set_xlabel(\"Platform\")\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.legend(title=\"Sentiment\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Engagement vs Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total engagement\n",
    "df[\"total_engagement\"] = df[\"retweets\"] + df[\"likes\"] + df[\"replies\"]\n",
    "\n",
    "# Engagement by sentiment\n",
    "sentiment_engagement = df.groupby(\"vader_sentiment\")[\"total_engagement\"].agg(\n",
    "    [\"mean\", \"median\", \"std\"]\n",
    ")\n",
    "\n",
    "print(\"Engagement Statistics by Sentiment:\")\n",
    "print(sentiment_engagement)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "df.boxplot(column=\"total_engagement\", by=\"vader_sentiment\", ax=axes[0])\n",
    "axes[0].set_title(\"Engagement Distribution by Sentiment\")\n",
    "axes[0].set_xlabel(\"Sentiment\")\n",
    "axes[0].set_ylabel(\"Total Engagement\")\n",
    "plt.sca(axes[0])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Bar plot of means\n",
    "sentiment_engagement[\"mean\"].plot(kind=\"bar\", ax=axes[1], color=\"skyblue\")\n",
    "axes[1].set_title(\"Average Engagement by Sentiment\")\n",
    "axes[1].set_xlabel(\"Sentiment\")\n",
    "axes[1].set_ylabel(\"Average Total Engagement\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save enriched dataset\n",
    "output_file = \"../../results/sentiment_analysis_results.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Results saved to {output_file}\")\n",
    "\n",
    "# Uncomment to save to S3\n",
    "# data_client = SocialMediaDataAccess(region=AWS_REGION)\n",
    "# data_client.save_results(df, 'sentiment_analysis_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "### VADER Analysis\n",
    "- **Positive**: X% of posts\n",
    "- **Negative**: Y% of posts\n",
    "- **Neutral**: Z% of posts\n",
    "- **Average compound score**: [value]\n",
    "\n",
    "### AWS Comprehend Analysis (if enabled)\n",
    "- **Agreement with VADER**: X%\n",
    "- **Main differences**: [describe]\n",
    "\n",
    "### Engagement Insights\n",
    "- [Sentiment type] posts receive highest engagement\n",
    "- Average engagement: [value]\n",
    "\n",
    "### Platform Differences\n",
    "- [Platform] shows most positive sentiment\n",
    "- [Platform] shows most negative sentiment\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "1. **For most use cases**: Use VADER for cost-effectiveness and speed\n",
    "2. **For high-accuracy needs**: Use Comprehend despite cost\n",
    "3. **For multi-language**: Must use Comprehend\n",
    "4. **For large-scale**: Use VADER first, then Comprehend on subset\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Misinformation Detection**: Run `03-misinformation-detection.ipynb`\n",
    "2. **Network Analysis**: Run `04-network-analysis.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
