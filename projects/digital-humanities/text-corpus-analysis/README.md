# Historical Text Corpus Analysis at Scale

Large-scale text analysis using NLP and machine learning for authorship attribution, stylometry, semantic change tracking, and cultural evolution across historical corpora.

## Quick Start by Tier

**New here?** Start with tier-0 (60-90 min, free) to learn authorship attribution with BERT.

### ðŸŸ¢ Tier 0: Authorship Attribution with BERT (60-90 min, FREE)
**[Launch tier-0 project â†’](tier-0/)**

Train BERT for authorship attribution on historical texts:
- âœ… Real historical corpus (~1.5GB, 50 texts from Project Gutenberg, 1800-1920)
- âœ… Fine-tune BERT for authorship classification (10 authors: Austen, Dickens, Twain, Poe, etc.)
- âœ… Stylometric analysis with attention patterns
- âœ… Feature importance for writing style characteristics
- âœ… Complete in 60-90 minutes
- âœ… No AWS account needed (Colab or Studio Lab)

**Platform**: Google Colab or SageMaker Studio Lab
**Cost**: $0

[View tier-0 README â†’](tier-0/README.md) | [Open in Colab â†’](https://colab.research.google.com/github/scttfrdmn/research-jumpstart/blob/main/projects/digital-humanities/text-corpus-analysis/tier-0/historical-text-analysis.ipynb)

---

### ðŸŸ¡ Tier 1: Multi-Language Corpus Analysis (4-8 hours, FREE)
**[Launch tier-1 project â†’](tier-1/)**

Cross-lingual analysis with multilingual transformers:
- âœ… 10GB multilingual corpus (6 languages: English, French, German, Spanish, Italian, Latin)
- âœ… Ensemble transformer models (BERT, RoBERTa, XLM-R)
- âœ… Cross-lingual stylometry and author attribution
- âœ… Semantic change tracking across languages
- âœ… Persistent storage for long training runs (Studio Lab)
- âœ… Still free, no AWS account

**Platform**: SageMaker Studio Lab
**Cost**: $0

[View tier-1 README â†’](tier-1/README.md)

---

### ðŸŸ  Tier 2: Research-Scale Text Analysis (2-3 days, $500-1K per 100K documents)
**[Launch tier-2 project â†’](tier-2/)**

Production infrastructure for digital humanities research:
- âœ… CloudFormation one-click deployment
- âœ… 100GB+ text archives on S3 (HathiTrust, Project Gutenberg, Internet Archive)
- âœ… Distributed NLP pipelines with AWS Comprehend
- âœ… Large-scale topic modeling (LDA, BERTopic on 100K+ documents)
- âœ… Word embeddings and semantic change analysis
- âœ… Full-text and semantic search with OpenSearch
- âœ… Publication-ready outputs and visualizations

**Platform**: AWS with CloudFormation
**Cost**: $500-1K for 100K documents + $50/month infrastructure

[View tier-2 README â†’](tier-2/README.md)

---

### ðŸ”´ Tier 3: Enterprise Digital Humanities Platform (Ongoing, $2K-5K/month)
**[Launch tier-3 project â†’](tier-3/)**

Production platform for research teams and departments:
- âœ… Multi-user collaboration with shared corpora (millions of documents)
- âœ… AI-assisted interpretation (Amazon Bedrock for contextual analysis)
- âœ… Distributed processing with AWS Batch
- âœ… Knowledge graph database (Neptune) for entity linking
- âœ… Integration with library systems (HathiTrust, OCLC APIs)
- âœ… Interactive dashboards (QuickSight) for exploration
- âœ… Team workflows with version control

**Platform**: AWS multi-account with enterprise support
**Cost**: $2K-5K/month (scales with corpus size)

[View tier-3 README â†’](tier-3/README.md)

---

## What You'll Learn

Across all tiers, this project teaches:
- Transfer learning with BERT for authorship attribution
- Stylometric analysis and feature extraction for writing style
- Multi-language text analysis with multilingual transformers (XLM-R)
- Large-scale topic modeling (LDA, BERTopic) on 100K+ documents
- Word embeddings and semantic change tracking over time
- Distributed NLP pipelines at scale

## Technologies & Tools

- **Data sources**: HathiTrust (17M volumes), Project Gutenberg (70K books), Internet Archive
- **Languages**: Python 3.9+
- **Core libraries**: pandas, numpy, scipy, scikit-learn
- **NLP tools**: transformers (BERT, RoBERTa, XLM-R), spaCy, NLTK, gensim
- **Topic modeling**: Latent Dirichlet Allocation (LDA), BERTopic, Word2Vec
- **Cloud services** (tier 2+): S3, Comprehend (NLP), SageMaker (training), OpenSearch (full-text search), Bedrock (AI), Neptune (knowledge graphs)

## Project Structure

```
text-corpus-analysis/
â”œâ”€â”€ tier-0/              # BERT authorship (60-90 min, FREE)
â”‚   â”œâ”€â”€ historical-text-analysis.ipynb
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ tier-1/              # Multi-language (4-8 hours, FREE)
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ environment.yml
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ tier-2/              # Research-scale (2-3 days, $500-1K/100K docs)
â”‚   â”œâ”€â”€ cloudformation/
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tests/
â”‚   â””â”€â”€ README.md
â””â”€â”€ tier-3/              # Enterprise platform (ongoing, $2K-5K/mo)
    â”œâ”€â”€ cloudformation/
    â”œâ”€â”€ notebooks/
    â”œâ”€â”€ src/
    â”œâ”€â”€ infrastructure/
    â””â”€â”€ README.md
```

## Progression Path

```
Tier 0           â†’ Tier 1          â†’ Tier 2            â†’ Tier 3
BERT Authorship    Multi-language     Research-Scale      Enterprise
50 texts           5,000 texts        100K+ docs          Millions
60-90 min          4-8 hours          2-3 days            Ongoing
FREE               FREE               $500-1K/100K        $2K-5K/mo
```

You can:
- âœ… Skip tiers if you have AWS experience and large corpus needs
- âœ… Stop at any tier - tier-1 is great for dissertations, tier-2 for grant-funded projects
- âœ… Mix and match - use tier-0 for method testing, tier-2 for publications

[Understanding tiers â†’](../../../docs/projects/tiers.md)

## Digital Humanities Applications

- **Authorship attribution**: Identify anonymous or disputed authorship (90-95% accuracy with BERT)
- **Stylometry**: Analyze writing style patterns, function words, linguistic signatures
- **Cultural evolution**: Track concept spread and cultural trends across time and geography
- **Semantic change**: Measure word meaning shifts over decades and centuries
- **Topic modeling**: Discover themes across 100K+ documents (LDA, BERTopic)
- **Distant reading**: Analyze thousands of novels for literary patterns

## Related Projects

- **[Text Analysis](../text-analysis/)** - Topic modeling and NLP techniques
- **[Linguistics - Corpus Linguistics](../../linguistics/corpus-linguistics/)** - Language analysis methods
- **[Social Science - Network Analysis](../../social-science/network-analysis/)** - Cultural network analysis

## Common Use Cases

- **Literary scholars**: Authorship attribution for disputed texts (Shakespeare, Federalist Papers)
- **Historians**: Track cultural concepts through 19th-century newspapers
- **Linguists**: Document language change through historical corpora (1800-2000)
- **Digital humanists**: Distant reading of thousands of novels for patterns
- **Archivists**: Automated metadata generation for manuscript collections
- **Students**: Explore literary themes and authorship in historical texts

## Cost Estimates

**Tier 2 Research-Scale (100,000 documents)**:
- **Storage (S3)**: 100GB corpus = $2.30/month
- **NLP preprocessing (Comprehend)**: 100K docs = $300-400
- **Topic modeling (SageMaker)**: ml.p3.2xlarge, 12 hours = $45-60
- **Search (OpenSearch)**: m5.large.search = $140/month
- **Total**: $500-1K for initial analysis + $150/month infrastructure

**Optimization tips**:
- Batch Comprehend API calls to reduce per-document costs
- Use spot instances for SageMaker training (60-70% savings)
- Archive infrequently-accessed texts to S3 Glacier ($0.004/GB/month)
- Cache embeddings and topic models for reuse

## Support

- **Questions**: [GitHub Discussions](https://github.com/scttfrdmn/research-jumpstart/discussions)
- **Issues**: [GitHub Issues](https://github.com/scttfrdmn/research-jumpstart/issues)
- **Office Hours**: [Every Tuesday](../../../docs/community/office-hours.md)

## Citation

If you use this project in your research, please cite:

```bibtex
@software{research_jumpstart_text_corpus,
  title = {Historical Text Corpus Analysis at Scale: Research Jumpstart},
  author = {Research Jumpstart Community},
  year = {2025},
  url = {https://github.com/scttfrdmn/research-jumpstart},
  note = {Accessed: [date]}
}
```

Also cite the appropriate data sources:
- **HathiTrust**: https://www.hathitrust.org
- **Project Gutenberg**: https://www.gutenberg.org
- **Internet Archive**: https://archive.org

## License

Apache 2.0 - See [LICENSE](../../../LICENSE) for details.

---

*Part of [Research Jumpstart](https://github.com/scttfrdmn/research-jumpstart) - Pre-built research workflows for cloud computing*
